{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back propagation своими руками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы построим нейросеть на numpy и обучим ее с помощью градиентного спуска.\n",
    "\n",
    "В numpy нет автоматического дифференцирования, поэтому нам придется самостоятельно считать градиент\n",
    "и \"тащить\" его через всю сеть (с конца в начало).\n",
    "\n",
    "Это задание будет полезно для более глубокого понимания работы back propagation \"под капотом\".\n",
    "\n",
    "Будем делать задание в несколько этапов:\n",
    "1. Подготовим данные.\n",
    "2. Построим сеть \"Linear + Tanh + Linear\" для регрессии, используя pytorch, обучим ее.\n",
    "С ней будем дальше сравниваться.\n",
    "3. Напишем линейный слой на numpy, научим его считать свой градиент.\n",
    "4. Напишем Tanh слой, научим его считать свой градиент.\n",
    "5. Напишем алгоритм back propagation, который будет распространять градиент с конца в начало.\n",
    "\n",
    "Учить все это будем на MSE обычным градиентным спуском (без батчей и с константным learning rate).\n",
    "Почему Tanh - для него более показательная производная.\n",
    "MSE - простой градиент, будет проще реализовать.\n",
    "Градиентный спуск сделаем тоже максимально простым, т.к. наш фокус в этом задании на слои сети, а не алгоритмы оптимизации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных\n",
    "\n",
    "Возьмем готовые данные из урока 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# В train.csv и test.csv лежат данные из урока 2 после препроцессинга\n",
    "df_train = pd.read_csv(\"train.csv\", index_col=0)\n",
    "x_train = df_train.copy()\n",
    "y_train = x_train.pop(\"charges\")\n",
    "\n",
    "df_test = pd.read_csv(\"test.csv\", index_col=0)\n",
    "x_test = df_test.copy()\n",
    "y_test = x_test.pop(\"charges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.427091</td>\n",
       "      <td>-0.456256</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.788033</td>\n",
       "      <td>0.368152</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.433000</td>\n",
       "      <td>-1.296022</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.504007</td>\n",
       "      <td>-0.297840</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.490084</td>\n",
       "      <td>0.439278</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0 -1.427091 -0.456256         0         1.0       0.0        0.0         1.0   \n",
       "2 -0.788033  0.368152         3         0.0       1.0        1.0         0.0   \n",
       "3 -0.433000 -1.296022         0         0.0       1.0        1.0         0.0   \n",
       "4 -0.504007 -0.297840         0         0.0       1.0        1.0         0.0   \n",
       "6  0.490084  0.439278         1         1.0       0.0        1.0         0.0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0               0.0               0.0               0.0               1.0  \n",
       "2               0.0               0.0               1.0               0.0  \n",
       "3               0.0               1.0               0.0               0.0  \n",
       "4               0.0               1.0               0.0               0.0  \n",
       "6               0.0               0.0               1.0               0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.307931\n",
       "2   -0.730599\n",
       "3    0.733813\n",
       "4   -0.779255\n",
       "6   -0.413988\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим сеть на PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAP49JREFUeJzt3Ql8VOW9//HfJJlshIQ9YQmyueDGpiJadxZBbW3vvSJ6xVKXunCrUjfqvyBdxGqLVkVpVYpaFddKFcuqqFTcQBRRQAQMZQlr9m2SzP/1eyYzzIQEkjAzZ8nn/Xodz8yZMzPnmRNmvj7b8fj9fr8AAAC4RILVBwAAABBNhBsAAOAqhBsAAOAqhBsAAOAqhBsAAOAqhBsAAOAqhBsAAOAqSdLK1NbWyvbt26Vt27bi8XisPhwAANAEOi1fcXGxdOvWTRISDl030+rCjQab3Nxcqw8DAAC0wNatW6VHjx6H3KfVhRutsQl+OJmZmVF9bZ/PJ4sWLZKRI0eK1+sVt3F7+VpDGSmf83EOnY9z2DJFRUWmciL4O34orS7cBJuiNNjEItykp6eb13XrD6Oby9caykj5nI9z6HycwyPTlC4ldCgGAACuQrgBAACuQrgBAACuQrgBAACuQrgBAACuQrgBAACuQrgBAACuQrgBAACuQrgBAACuQrgBAACuQrgBAACuQrgBAACu0uounBkrVdW1srOwQvZXWn0kAAC0btTcRMkX/ymQs//4vsz8OjFaLwkAAFqAcBMlyYmBj7K6NlqvCAAAWoJwEyXJSXXhxh+tVwQAAC1BuIkSb13NTQ01NwAAtN5w8/7778sll1wi3bp1E4/HI2+88cYh93/99ddlxIgR0rlzZ8nMzJRhw4bJwoULxQ5SqLkBAMAWLA03paWlMmDAAJk5c2aTw5CGm7fffltWrlwp5513nglHn3/+udimWYqaGwAAWu9Q8NGjR5ulqR5++OGI+/fdd5/MmzdP3nzzTRk0aFCDz6msrDRLUFFRkVn7fD6zRE1tTWAlHqmorBI3Cn5eUf3cbMbtZaR8zsc5dD7OYcs053vZ0fPc1NbWSnFxsXTo0KHRfaZPny7Tpk07aPuiRYskPT09asdSUXPg41ywaIkku3hE+OLFi8Xt3F5Gyud8nEPn4xw2T1lZWesIN3/84x+lpKRELrvsskb3mTx5skyaNCmi5iY3N1dGjhxp+u1EcxK/uz5ZYm6fde650rFt9IKTXWhq1n+M2jTo9XrFjdxeRsrnfJxD5+Mctkyw5cXV4eaFF14wNTLaLNWlS5dG90tJSTFLffrDFc0fr6SkA2PA/Z5EV/4wxuqzsyO3l5HyOR/n0Pk4h83TnO9kRw4Fnzt3rlx77bXy8ssvy/Dhw8UOdLSXN9FjbvtqmOwGAACrOC7cvPjiizJhwgSzvuiii8ROgiOmtIkKAABYw9JmKe0vs3HjxtD9zZs3y+rVq00H4Z49e5r+Mtu2bZNnn3021BR19dVXy5///GcZOnSo7Ny502xPS0uTrKwsscMlGEqlhnADAEBrrbn57LPPzBDu4DBu7firt6dMmWLu79ixQ/Ly8kL7//Wvf5Xq6mq5+eabpWvXrqHllltuEVvV3DBNMQAArbPm5txzzxW/v/H+KXPmzIm4v2zZMnHCJRgINwAAWMdxfW6ccGVw+twAAGAdwk0U0SwFAID1CDdRlFw3FJyaGwAArEO4iUHNDfPcAABgHcJNFNHnBgAA6xFuosjLUHAAACxHuIlBzY2PeW4AALAM4SaKaJYCAMB6hJsoSk6qGy1FzQ0AAJYh3MTkwplcFRwAAKsQbmJw+QX63AAAYB3CTRTR5wYAAOsRbqKIyy8AAGA9wk0Uebn8AgAAliPcxGSeGzoUAwBgFcJNTEZL1UbzZQEAQDMQbqKIPjcAAFiPcBNFDAUHAMB6hJsoYig4AADWI9xEEc1SAABYj3ATg5qbSjoUAwBgGcJNFKV6Ax9nhY/RUgAAWIVwE0UpdeGm0lcTzZcFAADNQLiJotSkRLOuoFkKAADLEG6iKM1bF26ouQEAwDKEm1g0S1FzAwCAZQg3UZQaVnPj93N9KQAArEC4iaLUumtL1fpFqmoYMQUAgBUIN1GUUldzoxgODgCANQg3UZSc6BGPBJqjGA4OAIA1CDdR5PF4pK5PMTU3AABYhHATZaFwU81EfgAAWIFwE2UHam4INwAAWIFwE2XJdZ9oeRXhBgAAKxBuYtYsxVBwAACsQLiJMpqlAACwFuEmyrwJgaHg9LkBAMAahJsY1dxU+miWAgDACoSbGHUoZig4AADWINxEGX1uAACwFuEmRuGmvIpmKQAArEC4iTJmKAYAwFqEmyijWQoAAGsRbqIsOTE4FJxmKQAArEC4idlQcC6/AACAFQg3sepQTLgBAMAShJsoS6n7RMu4cCYAAJYg3ERZcmJgXVZVHe2XBgAATUC4iTJqbgAAsBbhJkajpWiWAgDAGoSbKEupa5YqraRZCgAAKxBuYnThTGpuAACwBuEmRjU32qHY7w80UQEAgPgh3MQo3NT6RSqrmaUYAIBWFW7ef/99ueSSS6Rbt27i8XjkjTfeOOxzli1bJoMHD5aUlBTp16+fzJkzR+zYLKXodwMAQCsLN6WlpTJgwACZOXNmk/bfvHmzXHTRRXLeeefJ6tWr5dZbb5Vrr71WFi5cKHaR4BFJrZummH43AADEX5JYaPTo0WZpqlmzZknv3r3lT3/6k7nfv39/Wb58uTz00EMyatQosYv05ERz4UzCDQAArSzcNNeKFStk+PDhEds01GgNTmMqKyvNElRUVGTWPp/PLNEUfL10b6LsE58UllWIz5cqbhEsX7Q/Nztxexkpn/NxDp2Pc9gyzfledlS42blzp2RnZ0ds0/saWMrLyyUtLe2g50yfPl2mTZt20PZFixZJenp6TI6zprJcRDyy7IMVsqOd+0ZMLV68WNzO7WWkfM7HOXQ+zmHzlJWVuTPctMTkyZNl0qRJofsahHJzc2XkyJGSmZkZ9VSpf6xdOmTJjm1FctKgITK8fxdxi2D5RowYIV6vV9zI7WWkfM7HOXQ+zmHLBFteXBducnJyJD8/P2Kb3teQ0lCtjdJRVbrUpz9csfrxapMa+FgrawLv4zax/Ozswu1lpHzOxzl0Ps5h8zTnO9lR89wMGzZMli5dGrFN/y9bt9uJ9rlRpVwZHACAuLM03JSUlJgh3boEh3rr7by8vFCT0vjx40P733DDDbJp0ya58847Zd26dfL444/Lyy+/LLfddpvYSXpyoOamTKtuAABA6wk3n332mQwaNMgsSvvG6O0pU6aY+zt27AgFHaXDwOfPn29qa3R+HB0S/tRTT9lqGLhKr5ummKHgAADEn6V9bs4999xDXn+podmH9Tmff/652Fmb5GC44crgAADEm6P63DiFTuKnSioJNwAAxBvhJgYyUgIVYoQbAADij3ATA23rhoIXV1BzAwBAvBFuYllzQ7gBACDuCDcxkFFXc1NU4c7rEwEAYGeEmxjW3NAsBQBA/BFuYqAtHYoBALAM4SaGzVI6WupQ8/gAAIDoI9zEsOamptYv5T4uwQAAQDwRbmI0iV+CJ3CbfjcAAMQX4SYGPB4PnYoBALAI4SZG2qZ6zbqY4eAAAMQV4SbGsxRzCQYAAOKLcBMjXIIBAABrEG5ihEswAABgDcJNjPvccAkGAADii3ATh4n8AABA/BBuYoQ+NwAAWINwE+vrS1VQcwMAQDwRbmI9z02lL1ZvAQAAGkC4iXGzVGE54QYAgHgi3MRIu/RAzQ3hBgCA+CLcxEhWWrJZE24AAIgvwk2MZKUFam4KymiWAgAgngg3MW6WKq6olppaf6zeBgAA1EO4iXHNjSqiUzEAAHFDuIkRb2KCtElONLcLCDcAAMQN4SaG2qXTqRgAgHgj3MRQZqhTcVUs3wYAAIQh3MRQu7pww3BwAADih3ATQ0zkBwBA/BFuYoi5bgAAiD/CTQxlcQkGAADijnATQ+3qLsHALMUAAMQP4SYOzVKF5YyWAgAgXgg3MUSHYgAA4o9wE4eh4DRLAQAQP4SbOEzixzw3AADED+EmDs1Sem0pv58rgwMAEA+EmzhcW6qqulYqfLWxfCsAAFCHcBNDelVwb6LH3N7H9aUAAIgLwk0MeTwe6dAmUHuzr4Th4AAAxAPhJsY6tEkx672llbF+KwAAQLiJvY7BmptSam4AAIgHam5irD3hBgCAuCLcxBg1NwAAxBfhJsZCHYpplgIAIC4IN3EKN3sJNwAAxAXhJsZolgIAIL4INzFGh2IAAOKLcBOnmpu9JcxzAwBAPBBu4tTnpqiiWnw1XF8KAIBYI9zE4eKZnsDlpWQ/15cCACDmCDcxlpjgkfZ1VwdnODgAALFHuImD9ules+bimQAAtIJwM3PmTOnVq5ekpqbK0KFD5ZNPPjnk/g8//LAce+yxkpaWJrm5uXLbbbdJRUWF2FnH0MUzub4UAACuDjcvvfSSTJo0SaZOnSqrVq2SAQMGyKhRo2TXrl0N7v/CCy/I3Xffbfb/5ptv5Omnnzav8atf/UrsjFmKAQCInySx0IwZM+S6666TCRMmmPuzZs2S+fPny+zZs02Iqe/DDz+UM888U6644gpzX2t8xo0bJx9//HGj71FZWWmWoKKiIrP2+Xxmiabg69V/3XbpgY95T3F51N8znhorn5u4vYyUz/k4h87HOWyZ5nwve/x+v18sUFVVJenp6fLqq6/KpZdeGtp+9dVXS0FBgcybN6/BmpubbrpJFi1aJKeddpps2rRJLrroIrnqqqsarb259957Zdq0aQ2+lr5/PMzPS5BF2xLkB9m18j99GA4OAEBzlZWVmcqNwsJCyczMtGfNzZ49e6Smpkays7Mjtuv9devWNfgcLZQ+7wc/+IFoJquurpYbbrjhkM1SkydPNk1f4TU32ldn5MiRh/1wWpIqFy9eLCNGjBCvN9CJWO35KE8WbVsnbTrmyJgxA8WpGiufm7i9jJTP+TiHzsc5bJlgy4vtm6Waa9myZXLffffJ448/bjofb9y4UW655Rb57W9/K7/+9a8bfE5KSopZ6tMfrlj9eNV/7ZysQA3RvjKfK34wY/nZ2YXby0j5nI9z6Hycw+ZpzndyszsUL1iwQJYvXx4x2mngwIGmVmX//v1Nfp1OnTpJYmKi5OfnR2zX+zk5OQ0+RwOMNkFde+21ctJJJ8mPf/xjE3amT58utbX2be7p3DYQrnYXcwkGAABirdnh5o477ghVDa1Zs0Z++ctfypgxY2Tz5s0RzT+Hk5ycLEOGDJGlS5eGtmlA0fvDhg1rtL0tISHykDUgKYu6DjUJ4QYAgPhpdrOUhpjjjz/e3H7ttdfk4osvNrUnOpRbQ05zaBjSDsSnnHKK6SCsc9iUlpaGRk+NHz9eunfvbmpm1CWXXGJGWA0aNCjULKW1Obo9GHLsHG5Kq2qktLJa2qQ4qjUQAABHafavrNa4aA2KWrJkiQkgqkOHDs3q7KPGjh0ru3fvlilTpsjOnTtN85Y2ewU7Gefl5UXU1Py///f/xOPxmPW2bdukc+fOJtj8/ve/Fztrk5woad5EKffVyJ6SSsINAAB2Cjc6UklrXHS+GZ1NWCfRUxs2bJAePXo0+wAmTpxolsY6EEccbFKSmcBPFyfRQNapbbJs3Vduws1RHdtYfUgAALhWs/vcPPbYYyZk6Pw0TzzxhGk2Uv/617/kwgsvjMUxukLnDDoVAwBgy5qbnj17yltvvXXQ9oceeihax+RKdCoGAMCmNTfacVhHSQXpTMI6w7BOpKezDqNhhBsAAGwabn7+85+b/jVKL39w+eWXm8sYvPLKK3LnnXfG4hhdoXNGqlnvLmGuGwAAbBVuNNjoqCalgebss88212maM2eOGRqOhlFzAwCATcONTpYXnA1Yh4IH57bR6zXpdZ/QMMINAAA2DTc64d7vfvc7ee655+S9994zV+UOTu5X/yKYOIBwAwCATcONziKsnYp1bpp77rlH+vXrZ7br0PAzzjgjFsfornBTUmnrS0UAANDqhoKffPLJEaOlgh588EFbXwLBap0yks3aV+OXwnKftEsP3AcAANHV4oscrVy5Ur755htzW681NXjw4Ggel+ukJCVKVprXBBu9OjjhBgAAm4SbXbt2mWtCaX+bdu3amW0FBQVy3nnnydy5c831ntB405QJNyWVcnR2Wz4mAADs0Ofm//7v/6SkpETWrl0r+/btM8tXX31lLpr5i1/8IhbH6BpcggEAABvW3OhVu3UIeP/+/UPbtFlq5syZMnLkyGgfnys7Fe8qYiI/AABsU3Ojc9x4vd6Dtuu24Pw3aFhOVmCW4vyiCj4iAADsEm7OP/98ueWWW2T79u2hbdu2bZPbbrtNLrjggmgfn6tkZwbCzU7CDQAA9gk3jz32mOlf06tXL+nbt69ZevfubbY9+uijsTlKl8gJhptCam4AALBNnxu9zIJO4qf9btatW2e2af+b4cOHx+L4XCUnK9DnhpobAABsNs+Nx+ORESNGmAXNb5bSDsU6S7F+jgAAwIJw88gjjzT5BRkO3rgubQPhpqqmVvaVVknHjEBNDgAAiHO4eeihh5r0YloTQbhpXHJSgrkMw56SKtM0RbgBAMCicKNX/Eb0mqY03Ohw8BO6ZfGxAgBg9WgpHJmudXPd7CxkIj8AAGKBcGPVXDeF5fF+awAAWgXCjVVz3TCRHwAAMUG4ibPsYLMU15cCACAmCDcW1dzkM0sxAADWhpsHHnhAyssP9BP597//LZWVBzrFFhcXy0033RT9I3TpxTNplgIAwOJwM3nyZBNggkaPHm0umBlUVlYmf/nLX6J/hC7tUFxY7pMKX43VhwMAQOsNN3q5gEPdR9NkpiZJmjfR3OYCmgAARB99buJMZ3GmaQoAgNgh3FggO7Pu6uB0KgYAwNqrgj/11FOSkZFhbldXV8ucOXOkU6dO5n54fxwcWtesNLOmUzEAABaGm549e8qTTz4Zup+TkyPPPffcQfug6Zdg2F7ALMUAAFgWbrZs2RL1N2+turcP1NwQbgAAiD763FigW7tAuPnPfmpuAACwLNysWLFC3nrrrYhtzz77rPTu3Vu6dOki119/fcSkfmhc97pwQ80NAAAWhpvf/OY3snbt2tD9NWvWyDXXXCPDhw+Xu+++W958802ZPn16DA7RvTU3RRXVUlzhs/pwAABoneFm9erVcsEFF4Tuz507V4YOHWo6GU+aNEkeeeQRefnll2N1nK6SkZIkWWlec3t7QYXVhwMAQOsMN/v375fs7OzQ/ffee89cgiHo1FNPla1bt0b/CF2KpikAACwONxpsNm/ebG5XVVXJqlWr5PTTTw89rvPceL2B2gg0vWlqG8PBAQCwJtyMGTPG9K354IMPzEU009PT5ayzzgo9/uWXX0rfvn2je3Qu1r1dYK4bwg0AABbNc/Pb3/5WfvKTn8g555xjZil+5plnJDk5OfT47NmzZeTIkVE+PPdirhsAACwON3qZhffff18KCwtNuElMDFzZOuiVV14JXZoBTW+WYjg4AAAWXltKZWVlNbi9Q4cO0Tie1tfnhon8AACwJtz87Gc/a9J+2jyFw+vR7sDFM6traiUpkcmiAQCIa7jRK4AfddRRMmjQIPH7/VF589asU0aKJCcmSFVNreQXV4aGhgMAgDiFmxtvvFFefPFFMxx8woQJ8r//+780RR2BhASPdG2XKt/vLTNNU4QbAACio8ltITNnzpQdO3bInXfeaS61kJubK5dddpksXLiQmpwW6pZFp2IAAKKtWR09UlJSZNy4cbJ48WL5+uuv5YQTTpCbbrpJevXqJSUlJVE/OLdjIj8AAKKvxb1YExISxOPxmFqbmpqa6B5VK5HbIVBzs3VfmdWHAgBA6ww3lZWVpt/NiBEj5JhjjjFXBn/sscckLy+POW5aoGeHdLPOI9wAABD/DsXa/KRXAte+NjosXEOOTuyHliPcAABgYbiZNWuW9OzZU/r06WOuCK5LQ15//fVoHl+rCDc7CivEV1MrXua6AQAgfuFm/Pjxpo8Noqdz2xRJSUqQyupa2VFQIT07BsIOAACI0yR+saBDzB988EHZuXOnDBgwQB599FE57bTTGt2/oKBA7rnnHlNDtG/fPjOx4MMPP2yuWu40GhZzO6TLxl0lpt8N4QYAgCNn6Zz/L730kkyaNEmmTp0qq1atMuFm1KhRsmvXrgb3r6qqMp2Zt2zZIq+++qqsX79ennzySenevbs4Ff1uAACw+MKZ0TRjxgy57rrrzIzHwX498+fPN9enuvvuuw/aX7drbc2HH34oXq/XbNM5dpyMcAMAgEvCjdbCrFy5UiZPnhwxd87w4cNlxYoVDT7nn//8pwwbNkxuvvlmmTdvnnTu3FmuuOIKueuuuyQxMbHR4eu6BBUVFZm1z+czSzQFX685r9stK8Wsv99TEvXjibaWlM9p3F5Gyud8nEPn4xy2THO+lz1+i66CuX37dtOcpLUwGliC9PIOOhLr448/Pug5xx13nGmSuvLKK83Q9I0bN5r1L37xC9O01ZB7771Xpk2bdtD2F154QdLTre/Au2afR55anyi5bfxy+8lMhggAQEPKyspMhUZhYaFkZmaKbZulmqu2tla6dOkif/3rX01NzZAhQ2Tbtm2mQ3Jj4UZrhrRfT3jNjc7VM3LkyMN+OC1JlXppCu0XFGw2O5x++cXy1PoVUlTrlTFjRomdtaR8TuP2MlI+5+McOh/nsGWCLS9NYVm40QkANaDk5+dHbNf7OTk5DT6na9eu5gcnvAmqf//+ZqSVNnMlJyc3eD0sXerT14nVj1dzXrtX50DAKiyvlrJqkaw0+/+gxvKzswu3l5HyOR/n0Pk4h83TnO9ky0ZLaRDRmpelS5dG1Mzo/fBmqnBnnnmmaYrS/YI2bNhgQk9DwcYJ2qQkSaeMwLFzjSkAABw+FFybi3Qo9zPPPCPffPON3HjjjVJaWhoaPaUTB4Z3ONbHdbTULbfcYkKNjqy67777TAdjJ9O5bhThBgCAI2dpn5uxY8fK7t27ZcqUKaZpaeDAgbJgwQLJzs42j+sFOXUEVZD2lVm4cKHcdtttcvLJJ5sOyRp0dLSU04eDf55XIN9zAU0AAI6Y5R2KJ06caJaGLFu27KBt2mT10UcfiZscVVdz8/3eMqsPBQAAx7O0WQoBvTu3MevNe0r4SAAAOEKEGxvo3SnDrDfvKbX6UAAAcDzCjQ307hiouckvqpTSymqrDwcAAEcj3NhAVrpXOrQJDAffspfaGwAAjgThxiZ6dwr2uyHcAABwJAg3dgs3uwk3AAAcCcKNTVBzAwBAdBBubBZuNtEsBQDAESHc2AQ1NwAARAfhxiZ61Q0HLyz3yf7SKqsPBwAAxyLc2ERacqJ0y0o1t2maAgCg5Qg3trwMAyOmAABoKcKNHTsV7+YaUwAAtBThxkb6dg5cY2rjLsINAAAtRbixkaO7tDVrwg0AAC1HuLGRY7IzQteXqvDVWH04AAA4EuHGRjq3TZHM1CSp9dOpGACAliLc2IjH45GjswNNUxvyi60+HAAAHIlwY9OmKfrdAADQMoQbm+lX16n423xGTAEA0BKEG5vW3GzYRbMUAAAtQbix6XDw7/eWSWU1I6YAAGguwo3NZGemSNvUJKmp9XMZBgAAWoBwY8cRU10CTVP0uwEAoPkINzZ0TN1w8G8ZDg4AQLMRbmwcbtbtpFMxAADNRbixof5dM8366x1FVh8KAACOQ7ixoePrws1/9pdLYbnP6sMBAMBRCDc2lJXule7t0sztb6i9AQCgWQg3NnV8t0DtDeEGAIDmIdzYvGnq6+30uwEAoDkINzZFp2IAAFqGcGNTJ9Q1S+lEflXVtVYfDgAAjkG4sake7dOkbUqSVNXUyne7uUI4AABNRbix8WUY+tfV3tDvBgCApiPcOKBT8Vo6FQMA0GSEGxs7sXuWWX+1rdDqQwEAwDEINzY2MDcQbtZsK5TqGjoVAwDQFIQbG+vTKUMyUpKk3Fcj3+6iUzEAAE1BuLGxhASPnNwjUHuzemuB1YcDAIAjEG5sbmBuO7P+gnADAECTEG5sbkBduKHmBgCApiHcOKTmZkN+sZRVVVt9OAAA2B7hxuayM1MlJzNVav06JJyLaAIAcDiEGwcYUDcknH43AAAcHuHGQf1uVuXtt/pQAACwPcKNA5zaq4NZf7plv/j9fqsPBwAAWyPcOIDOdZOclCB7Sipl855Sqw8HAABbI9w4QEpSogzsEWia+nTLPqsPBwAAWyPcOMRpvQNNU59spt8NAACHQrhxiFPrwg01NwAAHBrhxiEG92wnCR6RvH1lsrOwwurDAQDAtgg3DtE21SsndAvMd/Px5r1WHw4AALZFuHGQoXVNUyu+I9wAAGDrcDNz5kzp1auXpKamytChQ+WTTz5p0vPmzp0rHo9HLr30UmkNzjy6k1l/8O0e5rsBAMCu4eall16SSZMmydSpU2XVqlUyYMAAGTVqlOzateuQz9uyZYvcfvvtctZZZ0lrqrlJTkyQbQXlsmVvmdWHAwCALVkebmbMmCHXXXedTJgwQY4//niZNWuWpKeny+zZsxt9Tk1NjVx55ZUybdo06dOnj7QW6clJMviowHw3y7/dbfXhAABgS0lWvnlVVZWsXLlSJk+eHNqWkJAgw4cPlxUrVjT6vN/85jfSpUsXueaaa+SDDz445HtUVlaaJaioKHBlbZ/PZ5ZoCr5etF833Jl9OshHm/bJ+xt2y+WndJd4ikf5rOb2MlI+5+McOh/nsGWa871sabjZs2ePqYXJzs6O2K73161b1+Bzli9fLk8//bSsXr26Se8xffp0U8NT36JFi0wNUSwsXrxYYqZE/5MkH2zIlzfnvy2JHom7mJbPJtxeRsrnfJxD5+McNk9ZWZkzwk1zFRcXy1VXXSVPPvmkdOoU6Fx7OForpH16wmtucnNzZeTIkZKZmRn1VKl/rCNGjBCv1yuxUFPrl6c3LpOCcp90O3GYDDmqvcRLPMpnNbeXkfI5H+fQ+TiHLRNsebF9uNGAkpiYKPn5+RHb9X5OTs5B+3/33XemI/Ell1wS2lZbW2vWSUlJsn79eunbt2/Ec1JSUsxSn/5wxerHK6avLSJnH9NZ/vnFdln27T45vV+XmLyPVeWzC7eXkfI5H+fQ+TiHzdOc72RLOxQnJyfLkCFDZOnSpRFhRe8PGzbsoP2PO+44WbNmjWmSCi4//OEP5bzzzjO3tUamNRhxfKAZb8k3kaEQAADYoFlKm4yuvvpqOeWUU+S0006Thx9+WEpLS83oKTV+/Hjp3r276Tuj8+CceOKJEc9v1y4weqj+djc759jOkpTgkY27SmTznlLp3amN1YcEAIBtWB5uxo4dK7t375YpU6bIzp07ZeDAgbJgwYJQJ+O8vDwzggoHZKZ65fQ+HWX5xj2y9Jt8ufas1jMcHgAA24cbNXHiRLM0ZNmyZYd87pw5c6Q1Gt6/iwk3i78m3AAAEI4qEYe6oH+gZuvTLftkb8mBeXwAAGjtCDcOldshXU7qniW1fpG31+yw+nAAALANwo2D/XBAN7N+8wvCDQAAQYQbB7t4QFfxeEQ+2bJPtheUW304AADYAuHGwbpmpcmpvTqY2299ud3qwwEAwBYINy5pmnrjc8INAACKcONwF53UVZITE+TrHUWy5j+FVh8OAACWI9w4XPs2yXLhiYHrcL34aZ7VhwMAgOUINy5w+WmBa2r9c/V2Ka2stvpwAACwFOHGBYb16Si9OqZLSWW1zP+SYeEAgNaNcOMCHo9Hxp7a09x+ZsUW8fv9Vh8SAACWIdy4xOWn5kqqN0HWbi+SFZv2Wn04AABYhnDjoo7Fl50S6Hvz5PubrD4cAAAsQ7hxkWt+0NvMWPzu+t2yIb/Y6sMBAMAShBsXOapjG7nwhMCw8Mfe2Wj14QAAYAnCjctMPL+fWb/55XZZt7PI6sMBACDuCDcuc0K3LDNrsQ6YmrFog9WHAwBA3BFuXOi2EUdLgkdk0df5sipvv9WHAwBAXBFuXKhfl7byk8E9zO2p89ZKTS3z3gAAWg/CjUvddeFx0jYlSdZsK5SXP9tq9eEAABA3hBuX6tw2RW4bcYy5/cCCdbKnpNLqQwIAIC4INy42fthRclxOW9lf5pNfvb6GyzIAAFoFwo2LJSUmyIzLBoo30WM6F7++apvVhwQAQMwRblzu+G6ZcuvwQPPUlHlfybfMXAwAcDnCTSvw87P7yLA+HaW0qkauf26lFFX4rD4kAABihnDTSpqnHrtikHTLSpXNe0rllhc/F19NrdWHBQBATBBuWomOGSky66ohkpKUYC6seeerX0ot898AAFyIcNOKnNyjncy8YrAkJnjkH59vkyn//IqAAwBwHcJNKzP8+Gz50/8MEI9H5O8f5cmkl1dLVTVNVAAA9yDctEKXDuouMy4bIEkJHnlj9Xb52ZxPZV9pldWHBQBAVBBuWqkfD+ohT159iqR5E2X5xj1y8SMfyOdcZBMA4AKEm1bsvGO7yOs3nSG9O7WR7YUV8j+zVsifFq2XCl+N1YcGAECLEW5auf5dM+WfE8+Ui07uKtW1fnn0nY0y5pEP5N11u7hcAwDAkQg3kLapXnls3CB54srB5oKbm3aXyoQ5n8plf1khK77bS8gBADgK4QaGx+OR0Sd1lSW3nWNmNNb5cD7dsl/GPfmRXPTIcnn5s61SXkVzFQDA/gg3iJCV7pXJY/rLe3ecJ/97ek9J9SbI1zuKzKR/w/6wTJ77NkGWbdgtldUEHQCAPSVZfQCwp5ysVPndpSfJ7SOPlbmfbpW/f/S9/Gd/uXy2J0E+e+5zM8rq9D4d5KyjO8uZ/TpJvy4ZZnJAAACsRrjBIbVLT5Ybzulrmqo+3bRHHnvzI1lXmia7iivNZRx0URkpSXJyjywZ1LOdHN81S47JzpCjOraR5CQqBwEA8UW4QZP75Ghw+a/etTJ69Nny3d4KeX/Dbvng2z2yKm+/lFRWy4ff7TVL6I8rwWOGmWutTs+O6dKjfbrktk8z6x7t0yTVm8inDwCIOsINWhR0dAi5Lj8/p6/U1PplQ36xrN5aIKvzCmR9frFs3FViAs+3u0rM0pBOGcnSpW2qGaHVRZfMFOmcoetUc79TRoq0b5MsmalJ5j0BAGgKwg2OmPa1CYadcaf1NNv8fr/sKKwwoUeDjvbX+c/+MrPeuq9MSqtqZE9JlVlkx2H+SBM80i7da5rIOqQnm9sd2ug6WTq0CWxvbxavZKV5JTMtsNYRX4QiAGh9CDeICQ0V3dqlmeXcY7tEPKbBp6DMJ9sKymV3caXsKq6oW1eG1rptT3GVlPtqzOSCoSDUDMmJCSboZKYlBUJPajD81L9ft071SrpXpNQnpjbKG+XPBAAQH4QbWBJ8tLlJl8PRS0HsL6uS/aU+KSirkn16u8wnBaWB2xqS9KKfBXXbiyp8UlTuk1q/SFVNrewpqTRL8yTJrz5bLG1TkurCkQafwO22uk4N3NfJDzUomXVq3WN1++iSkkSfIgCwAuEGtqadjrtmpZmlqbRmSPv7FFVUS2Fd4CksD4Qes66oNrcP3A8+Xi2F5VpbVGtep7iy2ixaw9QS2ix2IOzUBaSIQBQWkFK8EcFIb2ckJ0kCw+sBoNkIN3BlzZCGBl26t2t6KFI+n0/++dbbcua5F0hZtQQCUl0QKtZQVKHrutsR2w7c10CkKqtrTTObLi0rR2CIfahWqIFgFF5blNnAfUakAWiNCDdA/X8UCSIdM1Ikx9uyXjfaX8fUHNULPxqKDgpEDQQlDVRV1bXi90vd8wJhqSUC/Y4OBKGMlEQp3Z8gy6vWSlZa8iGDkS4ZqUlMzgjAcQg3QAxGj2kHZV1aSvsahQJRKBgF79cPRPVDks/UHvlD/Y7qd8ZOkC/2bWvysWjtUWMBKNTkVq9GKSusL5JewoNRawDiiXAD2JA2J+micwC1RG2tX0qrAsEnvBltf2mlfLRytfTse6yUVtU2HIzqtlXU9T3SWihddGh/S+hQ/oj+RGHNbOHBKLDtwO0DazpnA2gewg3gQtoROdjvSCQtok+Rd9vnMuacPuI9TLObNo0VH6b5rMEapbB9ddSaDuXXEW26tJRexiM8+ARrk8KDkD6e7vXIt3s9krlxr7TPSI0IVMx7BLQehBsAjQYK7XukS0voqLWyqpp6fY4aC0YHapgOrAM1RsGg1fS5jhLlbxtWHrTVm+hpNBwdaGI7uOYoPFTpBWNpYgPsj3ADICY0BLRJSTJL1yw5os7ZkYHnQF+j+oGosKxK8nbsFm96WympDASrkrr+R76aI69B0v5UwRCUkdJQU9qhw5Gu2yQTkIBYI9wAcE3nbG12e/vtt2XMmDNCzW7B/kfBcFS/qa1+eDpQkxQZnrSJTcOWThypi0jL5j/SqYs08DVcW3RwU1v9bSkJfqnxt+itgVaDcAOgFfU/kiNqYqs/gq1+YAqOVKvfvBa8rf2PaqMwxF+/uu9ZuUQytFx1tWPa1KZD99vWrYPbgs1woSU1ck1TG9yIcAMAzWhiy8lKbXFA0hFohwtH4bVGgVqlyH11eL/SmbTLfS2fJDK8JikQgrxm3SYlMRSagiFIyx0MTQeFpLoApft4ExOO6FiAaCHcAECcAlJacqJZumS2/HVKyitl3vwFcvpZ50pFjUhpZU2oH5IZtl9RLaV1lw7R28Gh/MHHQuuqQF8krUkKTAlwJDVJAToiLVRTpIEnOazmKCwkmaCYHFina5jSdXJgnZzgl6qaQBgEHB1uZs6cKQ8++KDs3LlTBgwYII8++qicdtppDe775JNPyrPPPitfffWVuT9kyBC57777Gt0fANxEA0SGV6Rnh/TDDuc/FO2LVO7TYHRgZJoJRaEA5JPSuqY4DU+NBSV9XC81onRd2eRRbYeSJHd9utgEIA0/B8JQYigUBW+nm9qjRElPTooISbpdO2+HPzeJmqVWw/Jw89JLL8mkSZNk1qxZMnToUHn44Ydl1KhRsn79eunSpctB+y9btkzGjRsnZ5xxhqSmpsof/vAHGTlypKxdu1a6d+9uSRkAwIl9kYJNbdlHUJOkfDW1EcHooJqj8GBUV2tUZvarMZ29dX8NUrrWvk3K9E2qex2RI2t6C5/eICIARYSfusB0UCgK7Kc1bnpf13o/uE0vccL0APZjebiZMWOGXHfddTJhwgRzX0PO/PnzZfbs2XL33XcftP/zzz8fcf+pp56S1157TZYuXSrjx48/aP/KykqzBBUVFYVGVegSTcHXi/br2oXby9caykj5nM+u57CN1yNttCapbctrk1RlVZW8vXCJDD3zbKnye8ICUI0JPvWDkD5WZvYJ3y9s/6pqMw1AcL6kfdU6HUB0R/SZsOMNhB3toB0MPuHbzba626mJHtm0yyO1X2yTtmnJgce9B0JUcF8NY07ki9HfaHNez+O3sGGzqqpK0tPT5dVXX5VLL700tP3qq6+WgoICmTdv3mFfo7i42NTwvPLKK3LxxRcf9Pi9994r06ZNO2j7Cy+8YN4bAOBu2mpWWSNSWSumn5JWDlXUeELbzNosnnr3D2zT51TVPabrGr8n5sed4PFLSoJeAFdC62RdJ/gjth14zB+2j4g3bH9v3TZ9PHg70aN9wcQxysrK5IorrpDCwkLJzMy0b83Nnj17pKamRrKzsyO26/1169Y16TXuuusu6datmwwfPrzBxydPnmyavcJrbnJzc01T1uE+nJakysWLF8uIESOOqC3crtxevtZQRsrnfJxDe9CmuPKqGinz1QTWdYv2YzLrsMfK62qQ9DFzu7Jatu7Il/TM9lJRHXgdrXky+/pqQjVNtX6PlNeIWSJ5olbrlJqUYK5jl+atW2vNUvh974H7odtmn7D7EfsmSJLHL5+tWC4/HhPd79Fgy4sjmqWOxP333y9z5841/XC0/01DUlJSzFKffuCx+vGK5WvbgdvL1xrKSPmcj3No9ecvkp4q0rEFzz0w2eTQBr9nNDiFApI2u4XCU/WBIGWCUqD5LRCoAvtVBAOVT5daqQjdrjG39Xk6GaXSdaA576D0dMR6tkmUy34U3e/R5ryWpeGmU6dOkpiYKPn5+RHb9X5OTs4hn/vHP/7RhJslS5bIySefHOMjBQAgPnS+oKw0Xbyxq3Xy1UQEn2AgCoSjwOPBfcy24P1DhKfysH2TE63tE2ZpuElOTjZDubUzcLDPTW1trbk/ceLERp/3wAMPyO9//3tZuHChnHLKKXE8YgAAnB+evIkJ5hIgsaA1U/Pnvy1WsrxZSvvDaAdiDSk6V40OBS8tLQ2NntIRUDrEe/r06ea+Dv2eMmWK6RDcq1cvMzeOysjIMAsAALCW1R2VLQ83Y8eOld27d5vAokFl4MCBsmDBglAn47y8PElIODAc7oknnjCjrP77v/874nWmTp1qRkYBAIDWzfJwo7QJqrFmKO0sHG7Lli1xOioAAOBEzpwhCAAAoBGEGwAA4CqEGwAA4CqEGwAA4CqEGwAA4CqEGwAA4CqEGwAA4CqEGwAA4CqEGwAA4CqEGwAA4CqEGwAA4Cq2uLZUPPn9frMuKiqKyWXey8rKzGt7vbG5lLyV3F6+1lBGyud8nEPn4xy2TPB3O/g7fiitLtwUFxebdW5urtWHAgAAWvA7npWVdch9PP6mRCAXqa2tle3bt0vbtm3F4/FE9bU1VWpo2rp1q2RmZorbuL18raGMlM/5OIfOxzlsGY0rGmy6desmCQmH7lXT6mpu9APp0aNHTN9DfxTd+MPYWsrXGspI+ZyPc+h8nMPmO1yNTRAdigEAgKsQbgAAgKsQbqIoJSVFpk6datZu5PbytYYyUj7n4xw6H+cw9lpdh2IAAOBu1NwAAABXIdwAAABXIdwAAABXIdwAAABXIdxEycyZM6VXr16SmpoqQ4cOlU8++UScYPr06XLqqaeaGZu7dOkil156qaxfvz5in3PPPdfM5hy+3HDDDRH75OXlyUUXXSTp6enmde644w6prq4WO7j33nsPOv7jjjsu9HhFRYXcfPPN0rFjR8nIyJD/+q//kvz8fMeUT//u6pdPFy2TE8/f+++/L5dccomZhVSP9Y033oh4XMdATJkyRbp27SppaWkyfPhw+fbbbyP22bdvn1x55ZVmkrR27drJNddcIyUlJRH7fPnll3LWWWeZf7M6K/UDDzwgdiijXnforrvukpNOOknatGlj9hk/fryZWf1w5/3++++3RRkPdw5/+tOfHnTsF154oWvOoWro36QuDz74oO3P4fQm/C5E63tz2bJlMnjwYDOCrF+/fjJnzpzoFEJHS+HIzJ0715+cnOyfPXu2f+3atf7rrrvO365dO39+fr7tP9pRo0b5//a3v/m/+uor/+rVq/1jxozx9+zZ019SUhLa55xzzjFl2rFjR2gpLCwMPV5dXe0/8cQT/cOHD/d//vnn/rffftvfqVMn/+TJk/12MHXqVP8JJ5wQcfy7d+8OPX7DDTf4c3Nz/UuXLvV/9tln/tNPP91/xhlnOKZ8u3btiijb4sWLdQSk/91333Xk+dP3v+eee/yvv/66Kcc//vGPiMfvv/9+f1ZWlv+NN97wf/HFF/4f/vCH/t69e/vLy8tD+1x44YX+AQMG+D/66CP/Bx984O/Xr59/3Lhxoce1/NnZ2f4rr7zS/O2/+OKL/rS0NP9f/vIXy8tYUFBgzsVLL73kX7dunX/FihX+0047zT9kyJCI1zjqqKP8v/nNbyLOa/i/WyvLeLhzePXVV5tzFH7s+/bti9jHyedQhZdNF/198Hg8/u+++87253BUE34XovG9uWnTJn96erp/0qRJ/q+//tr/6KOP+hMTE/0LFiw44jIQbqJAv3huvvnm0P2amhp/t27d/NOnT/c7jf5Q6j/U9957L7RNfxxvueWWRp+jf7QJCQn+nTt3hrY98cQT/szMTH9lZaXfDuFGvyQboj8kXq/X/8orr4S2ffPNN+Yz0B8VJ5SvPj1Xffv29dfW1jr+/NX/0dAy5eTk+B988MGIc5iSkmK++JV+SerzPv3009A+//rXv8wPy7Zt28z9xx9/3N++ffuI8t11113+Y4891h9vDf0w1vfJJ5+Y/b7//vuIH8aHHnqo0efYpYyNhZsf/ehHjT7HjedQy3v++edHbHPKOdxV73chWt+bd955p/kfz3Bjx4414epI0Sx1hKqqqmTlypWmajz8+lV6f8WKFeI0hYWFZt2hQ4eI7c8//7x06tRJTjzxRJk8ebKUlZWFHtNyahV6dnZ2aNuoUaPMxeHWrl0rdqDNFlp93KdPH1PVrdWlSs+dNgOEnz9tsurZs2fo/DmhfOF/j3//+9/lZz/7WcSFYZ1+/oI2b94sO3fujDhfeq0ZbQoOP1/ajHHKKaeE9tH99d/lxx9/HNrn7LPPluTk5Igya9X7/v37xY7/LvV8arnCaROGNgsMGjTINHeEV/nbvYzaHKFNFccee6zceOONsnfv3tBjbjuH2lwzf/5807RWnxPOYWG934VofW/qPuGvEdwnGr+dre7CmdG2Z88eqampiTiBSu+vW7dOnHbF9FtvvVXOPPNM8yMYdMUVV8hRRx1lwoG2/2p/AP3H9frrr5vH9cemofIHH7Oa/vBpO65+ie7YsUOmTZtm2rC/+uorc3z6xVH/R0OPP3jsdi9fOG33LygoMH0a3HL+wgWPp6HjDT9f+qMZLikpyXwxh+/Tu3fvg14j+Fj79u3FLrRvg56zcePGRVzM9Re/+IXpq6Dl+vDDD01o1b/vGTNm2L6M2r/mJz/5iTm+7777Tn71q1/J6NGjzY9aYmKi687hM888Y/qvaJnDOeEc1jbwuxCt783G9tEAVF5ebvrUtRThBiHaOUx/8JcvXx7xqVx//fWh25rEtSPnBRdcYL6U+vbta/tPUL80g04++WQTdvTH/uWXXz6ifzx29PTTT5vyapBxy/lrzfT/ji+77DLTifqJJ56IeGzSpEkRf9f6Y/Pzn//cdAa1++VDLr/88oi/ST1+/VvU2hz923Sb2bNnmxpj7RTstHN4cyO/C3ZHs9QR0qp+/T+N+r3E9X5OTo44xcSJE+Wtt96Sd999V3r06HHIfTUcqI0bN5q1lrOh8gcfsxv9v41jjjnGHL8enzblaG1HY+fPKeX7/vvvZcmSJXLttde69vwFj+dQ/950vWvXrojHtapfR9846ZwGg42e18WLF0fU2jR2XrWcW7ZscUwZg7S5WL9Lw/8m3XAO1QcffGBqSg/379KO53BiI78L0frebGwf/Vs/0v/xJNwcIU3aQ4YMkaVLl0ZU4+n9YcOGid3p/xHqH/A//vEPeeeddw6qAm3I6tWrzVprAJSWc82aNRFfRsEv4+OPP17sRoeTaq2FHr+eO6/XG3H+9ItI++QEz59Tyve3v/3NVOXr0Eu3nj/9+9QvxPDzpVXY2g8j/Hzpl672CwjSv239dxkMdrqPDuXVABFeZm26tENzRjDYaF8xDazaJ+Nw9Lxqn5Rgc47dyxjuP//5j+lzE/436fRzGF6bqt8zAwYMcMw59B/mdyFa35u6T/hrBPeJym/nEXdJhhkKrqM15syZY3r5X3/99WYoeHgvcbu68cYbzbDaZcuWRQxHLCsrM49v3LjRDFXUoX6bN2/2z5s3z9+nTx//2WeffdCQv5EjR5phgzqMr3PnzrYZKv3LX/7SlE+P/9///rcZmqhDEnUEQHBIow5zfOedd0w5hw0bZhanlC84Qk/LoCMpwjnx/BUXF5uho7roV9SMGTPM7eBIIR0Krv++tCxffvmlGYXS0FDwQYMG+T/++GP/8uXL/UcffXTEMGId7aFDbK+66ioz3FX/DeuQ1HgNIz5UGauqqszw9h49epjzEf7vMjjK5MMPPzSjbPRxHVr897//3Zyz8ePH26KMhyqfPnb77bebUTX6N7lkyRL/4MGDzTmqqKhwxTkMH8qtx6SjhOqz8zm88TC/C9H63gwOBb/jjjvMaKuZM2cyFNxudHy+nmid70aHhuvcDE6g/ygbWnSOA5WXl2d+CDt06GACnM41oX+I4fOkqC1btvhHjx5t5mDQ4KCBwufz+e1AhxZ27drVnJvu3bub+/qjH6Q/ijfddJMZcqn/0H784x+bf8hOKZ9auHChOW/r16+P2O7E86fz8zT0N6nDh4PDwX/961+bL30t0wUXXHBQuffu3Wt+CDMyMszQ0wkTJpgfo3A6R84PfvAD8xr6d6GhyQ5l1B/8xv5dBucuWrlypX/o0KHmByg1NdXfv39//3333RcRDqws46HKpz+Q+oOnP3Q6nFiHQ+s8TPX/Z9DJ5zBIQ4j+m9KQUp+dz6Ec5nchmt+b+jkOHDjQfD/r/3iFv8eR8NQVBAAAwBXocwMAAFyFcAMAAFyFcAMAAFyFcAMAAFyFcAMAAFyFcAMAAFyFcAMAAFyFcAMAAFyFcAOg1enVq5c8/PDDVh8GgBgh3ACIqZ/+9Kdy6aWXmtvnnnuu3HrrrXH7xOfMmWOuAl/fp59+Ktdff33cjgNAfCXF+f0A4IhVVVVJcnJyi5/fuXNnzgLgYtTcAIhbDc57770nf/7zn8Xj8Zhly5Yt5rGvvvpKRo8eLRkZGZKdnS1XXXWV7NmzJ/RcrfGZOHGiqfXp1KmTjBo1ymyfMWOGnHTSSdKmTRvJzc2Vm266SUpKSsxjy5YtkwkTJkhhYWHo/e69994Gm6Xy8vLkRz/6kXn/zMxMueyyyyQ/Pz/0uD5v4MCB8txzz5nnZmVlyeWXXy7FxcX89QA2RLgBEBcaaoYNGybXXXed7NixwywaSAoKCuT888+XQYMGyWeffSYLFiwwwUIDRrhnnnnG1Nb8+9//llmzZgW+wBIS5JFHHpG1a9eax9955x258847zWNnnHGGCTAaVoLvd/vttx90XLW1tSbY7Nu3z4SvxYsXy6ZNm2Ts2LER+3333XfyxhtvyFtvvWUW3ff++++P6WcGoGVolgIQF1rboeEkPT1dcnJyQtsfe+wxE2zuu+++0LbZs2eb4LNhwwY55phjzLajjz5aHnjggYjXDO+/ozUqv/vd7+SGG26Qxx9/3LyXvqfW2IS/X31Lly6VNWvWyObNm817qmeffVZOOOEE0zfn1FNPDYUg7cPTtm1bc19rl/S5v//976P2GQGIDmpuAFjqiy++kHfffdc0CQWX4447LlRbEjRkyJCDnrtkyRK54IILpHv37iZ0aODYu3evlJWVNfn9v/nmGxNqgsFGHX/88aYjsj4WHp6CwUZ17dpVdu3a1aIyA4gtam4AWEr7yFxyySXyhz/84aDHNEAEab+acNpf5+KLL5Ybb7zR1J506NBBli9fLtdcc43pcKw1RNHk9Xoj7muNkNbmALAfwg2AuNGmopqamohtgwcPltdee83UjCQlNf0raeXKlSZc/OlPfzJ9b9TLL7982Perr3///rJ161azBGtvvv76a9MXSGtwADgPzVIA4kYDzMcff2xqXXQ0lIaTm2++2XTmHTdunOnjok1RCxcuNCOdDhVM+vXrJz6fTx599FHTAVhHMgU7Goe/n9YMad8Yfb+GmquGDx9uRlxdeeWVsmrVKvnkk09k/Pjxcs4558gpp5wSk88BQGwRbgDEjY5WSkxMNDUiOteMDsHu1q2bGQGlQWbkyJEmaGhHYe3zEqyRaciAAQPMUHBtzjrxxBPl+eefl+nTp0fsoyOmtIOxjnzS96vfITnYvDRv3jxp3769nH322Sbs9OnTR1566aWYfAYAYs/j9/v9cXgfAACAuKDmBgAAuArhBgAAuArhBgAAuArhBgAAuArhBgAAuArhBgAAuArhBgAAuArhBgAAuArhBgAAuArhBgAAuArhBgAAiJv8f+eNjrb3V2rEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:03<00:00, 560.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final losses: [0.19233421981334686, 0.1923086941242218, 0.19228318333625793, 0.19225767254829407, 0.19223220646381378]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tqdm\n",
    "from IPython.display import clear_output\n",
    "from torch.optim import SGD\n",
    "\n",
    "lr, num_iter = 1e-2, 2_000\n",
    "torch.random.manual_seed(0)\n",
    "torch_model = nn.Sequential(\n",
    "    nn.Linear(len(x_train.columns), 32, bias=False),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(32, 1, bias=False),\n",
    ")\n",
    "\n",
    "\n",
    "# train_loop взят из урока 2\n",
    "def train_loop(model: nn.Module) -> list[float]:\n",
    "    t_x_train = torch.from_numpy(x_train.values.astype(np.float32))\n",
    "    t_y_train = torch.from_numpy(y_train.values.astype(np.float32))\n",
    "    torch.random.manual_seed(0)\n",
    "    losses = []\n",
    "    optim = SGD(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    for i in tqdm.trange(num_iter):\n",
    "        optim.zero_grad()\n",
    "        out = model(t_x_train)[:, 0]\n",
    "        loss = criterion(out, t_y_train)\n",
    "        loss.backward()\n",
    "        losses.append(loss.item())\n",
    "        optim.step()\n",
    "\n",
    "        # интерактивно рисуем графики каждые 100 итераций\n",
    "        if (i + 1) % 100 == 0:\n",
    "            # Чистим прошлый график\n",
    "            clear_output(wait=True)\n",
    "            # рисуем новый\n",
    "            plt.plot(losses)\n",
    "            plt.grid()\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.ylabel(\"MSE loss\")\n",
    "            plt.show()\n",
    "\n",
    "    return losses\n",
    "\n",
    "\n",
    "print(f\"Final losses: {train_loop(torch_model)[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь перейдем к самой интересной части."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейный слой на numpy\n",
    "\n",
    "Мы начнем с простого: forward pass линейного слоя.\n",
    "Для простоты исключим bias из слоя.\n",
    "\n",
    "Линейный слой принимает на вход метрицу $X$ размера $(N, K)$ и при прямом прохождении (forward pass) преобразует $X$ следующим образом:\n",
    "\n",
    "$$\n",
    "y = XW\n",
    "$$\n",
    "\n",
    "где $W$ - матрица размером $(K, d)$, $y$ - выход слоя размерности $(N, d)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randn(3, 4).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.testing import assert_allclose\n",
    "\n",
    "\"\"\"Допишите:\n",
    "- инициализацию весов\n",
    "- метод forward\n",
    "для заготовки ниже.\n",
    "\"\"\"\n",
    "\n",
    "class MyLinearLayer:\n",
    "    def __init__(self, dim_in: int, dim_out: int):\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_out = dim_out\n",
    "\n",
    "        # Напишите сюда правильную размерность\n",
    "        self.W = np.random.randn(dim_in, dim_out)\n",
    "\n",
    "    def get_params(self):\n",
    "        # Для удобства сделаем функцию, которая будет возвращать все параметры слоя\n",
    "        # В случае линейного это будет только вес\n",
    "        return (self.W,)\n",
    "\n",
    "    def forward(self, X: np.ndarray) -> np.ndarray:\n",
    "        y = X @ self.W\n",
    "        return y\n",
    "\n",
    "\n",
    "layer = MyLinearLayer(dim_in=3, dim_out=2)\n",
    "layer.W = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "assert_allclose(\n",
    "    layer.forward(np.array([[1, 2, 3], [4, 5, 6]])),\n",
    "    np.array([[22, 28], [49, 64]]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В лекции мы обсуждали back propagation. В частности,\n",
    "\n",
    "- градиент считается с конца в начала;\n",
    "- градиент сложной функции разбивается на произведение;\n",
    "\n",
    "Разберем в деталях.\n",
    "Возьмем задачу регрессии с данными:\n",
    "$$\n",
    "X = \\begin{bmatrix}\n",
    "  1 & 2 \\\\\n",
    "  4 & 5\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "и таргетом $$y = \\begin{bmatrix} 5 \\\\ 7 \\end{bmatrix} $$\n",
    "\n",
    "Допустим, мы решаем задачу одним линейным слоем без смещения и с весами\n",
    "$$W = \\begin{bmatrix} 4 \\\\ 5 \\end{bmatrix} $$\n",
    "\n",
    "Получим: $\\hat{y} = X W = \\begin{bmatrix}1 & 2 \\\\ 4 & 5 \\end{bmatrix} \\begin{bmatrix} 4 \\\\ 5 \\end{bmatrix} = \\begin{bmatrix} 1 \\cdot 4 + 2 \\cdot 5 \\\\ 4 \\cdot 4 + 5 \\cdot 5 \\end{bmatrix} = \\begin{bmatrix} 14 \\\\ 41 \\end{bmatrix}$.\n",
    "\n",
    "$$\n",
    "L = (14 - 5)^2 + (41 - 7)^2 = 1237\n",
    "$$\n",
    "\n",
    "Теперь к градиентам.\n",
    "$$\n",
    "dL (\\hat{y}(W)) = d_W (\\hat{y}) \\cdot dL(\\hat{y}) |_{\\hat{y} = X W}\n",
    "$$\n",
    "Везде в формуле $\\hat{y} = XW$.\n",
    "\n",
    "Переходим к подсчетам: $L = \\sum_{i=1}^N (\\hat{y}_i - y_i)^2$, тогда\n",
    "$$\n",
    "\\cfrac{\\partial L}{\\partial \\hat{y}} = 2 (\\hat{y} - y)\n",
    "$$\n",
    "Заметьте, этот градиент можно уже подсчитать, все числа нам даны.\n",
    "\n",
    "**Задание 2**: какой размерности должен быть вектор этого градиента? Отправьте в ЛМС одно целое число - размерность вектора."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мой ответ: \n",
    "\n",
    "Размерность градиента будет совпадать с размерностью y, то есть длина вектора будет 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3**: подставьте числа, подсчитайте вектор градиента и отправьте в ЛМС его компоненты, разделенные запятой (без разницы, с пробелом или без). Например, если вектор [4, 9, 2], то в ЛМС можно отправить \"4, 9, 2\" или же \"4,9,2\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мой ответ: \n",
    "\n",
    "Давайте посчитаем. Берем формулу:\n",
    "$\n",
    "\\cfrac{\\partial L}{\\partial \\hat{y}} = 2 (\\hat{y} - y),\n",
    "$\n",
    "где $ y = \\begin{bmatrix} 5 \\\\ 7 \\end{bmatrix} $ \n",
    "и $ \\hat{y} = \\begin{bmatrix} 14 \\\\ 41 \\end{bmatrix} $.\n",
    "\n",
    "Ответ будет \n",
    "$\n",
    "\\cfrac{\\partial L}{\\partial \\hat{y}} = \\begin{bmatrix} 18 \\\\ 68 \\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Зная вектор $\\cfrac{\\partial L}{\\partial \\hat{y}}$, можем получить градиент по весам - это уже делали в лекции.\n",
    "В лекции получилось:\n",
    "$$\n",
    "\\cfrac{\\partial L}{\\partial W} = X^T \\cdot \\cfrac{\\partial L}{\\partial \\hat{y}}\n",
    "$$\n",
    "Заметьте, что множители поменялись местами ($\\frac{\\partial L}{\\partial \\hat{y}}$ уехал вправо).\n",
    "\n",
    "**Задание 4**: подсчитайте этот градиент и отправьте в ЛМС (формат тот же, что в задании 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мой ответ: \n",
    "\n",
    "Давайте посчитаем по этой формуле\n",
    "\n",
    "$\n",
    "\\cfrac{\\partial L}{\\partial W} = X^T \\cdot \\cfrac{\\partial L}{\\partial \\hat{y}} = \n",
    "\\begin{bmatrix}\n",
    "  1 & 4 \\\\\n",
    "  2 & 5\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \n",
    "  18 \\\\ \n",
    "  68 \n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix} \n",
    "  290 \\\\ \n",
    "  376 \n",
    "\\end{bmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительно нужно подсчитать градиент по $X$:\n",
    "$$\n",
    "\\cfrac{\\partial L}{\\partial X} = \\cfrac{\\partial L}{\\partial \\hat{y}} \\cdot W^T\n",
    "$$\n",
    "\n",
    "Рассуждения те же, что в лекции (должно быть что-то в духе \"производная умножить на $W$\"), подгоняем по размерности - и получаем финальную формулу.\n",
    "\n",
    "Окей, но как теперь обобщить наш результат?\n",
    "Давайте добавим в каждый слой функцию `backward`, которая на вход будет принимать:\n",
    "- градиент по выходу (в нашем случае это $\\frac{\\partial L}{\\partial \\hat{y}}$) - это чтобы уметь обрабатывать случай, когда множители меняются местами;\n",
    "- вход слоя - т.к. мы используем $X^T$;\n",
    "- выход слоя - иногда удобнее через него формулу переписывать;\n",
    "\n",
    "и на выходе функция будет выдавать градиент по входу.\n",
    "Т.е. каждый слой научим преобразовывать:\n",
    "$$\n",
    "\\cfrac{\\partial L}{\\partial (out)} \\xrightarrow[]{\\text{backward}} \\cfrac{\\partial L}{\\partial (in)}\n",
    "$$\n",
    "\n",
    "Тогда алгоритм back propagation для N слоев будет следующим:\n",
    "1. Подсчитать градиент MSE: $\\cfrac{\\partial L}{\\partial y_N}$\n",
    "2. Подсчитать $\\cfrac{\\partial L}{\\partial W_N}$, зная производную из предыдущего пункта и входы сети.\n",
    "3. Вызвать `backward` и получить $\\cfrac{\\partial L}{\\partial y_{N-1}}$ из $\\cfrac{\\partial L}{\\partial y_N}$.\n",
    "4. Вернуться в п.2 для получения $\\cfrac{\\partial L}{\\partial W_{N-1}}$ (веса предыдущего слоя);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Добавьте в класс MyLinearLayerV2 функцию backward по описанию из ноутбука.\n",
    "Залейте в ЛМС код MyLinearLayerV2.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class MyLinearLayerV2(MyLinearLayer):\n",
    "    def backward(\n",
    "        self, output_grad: np.ndarray, layer_input: np.ndarray, layer_output: np.ndarray\n",
    "    ):\n",
    "        ...\n",
    "        # grad_by_inputs - это градиент по входу\n",
    "        # grad_by_W - это градиент по W (который X^T * ...)\n",
    "        return grad_by_inputs, [grad_by_W]\n",
    "\n",
    "\n",
    "# Прогоним над примером из текста\n",
    "layer = MyLinearLayerV2(dim_in=2, dim_out=1)\n",
    "layer.W = np.array([[4, 5]]).T\n",
    "x = np.array([[1, 2], [4, 5]])\n",
    "out = layer.forward(x)\n",
    "grad_mse = np.array([[18, 72]]).T\n",
    "grad_by_input, [grad_by_W] = layer.backward(grad_mse, x, None)\n",
    "\n",
    "assert_allclose(grad_by_W, np.array([[306], [396]]))\n",
    "# не используем в случае 1 слоя, но должны уметь считать\n",
    "assert_allclose(grad_by_input, np.array([[72, 90], [288, 360]]))\n",
    "\n",
    "print(\"Выход слоя:\\n\", out)\n",
    "print(\"Градиент MSE по выходу:\\n\", grad_mse)\n",
    "print(\"Градиент по W:\\n\", grad_by_W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нелинейный слой\n",
    "В нашей сети будет еще нелинейность.\n",
    "Разберемся с ней.\n",
    "\n",
    "Как мы увидели на линейном слое, нам нужно считать:\n",
    "- градиент по входу\n",
    "- градиент по всем параметрам слоя;\n",
    "\n",
    "В нелинейности нет параметров, поэтому нужна только одна формула: градиента по входу.\n",
    "\n",
    "Tanh применяет преобразование $y = \\tanh(x)$ поэлементно.\n",
    "В интернете находим, что $$(\\tanh x)' = \\cfrac{1}{\\cosh^2 x} = \\cfrac{2}{e^x + e^{-x}}$$\n",
    "\n",
    "Осталось собрать это с chain rule и не ошибиться с размерностями:\n",
    "$$\n",
    "d L (\\tanh (x)) = d L (t)|_{t=\\tanh(x)} \\cdot d(\\tanh x)\n",
    "$$\n",
    "\n",
    "Первый множитель говорит, как меняется $L$ при изменении $\\tanh(x)$ (меняем не $x$, а именно $\\tanh(x)$).\n",
    "Второе - как меняется $\\tanh(x)$ при изменении $x$.\n",
    "\n",
    "Тут проще думать поэлементно: было число $x_{ij}$, после слоя стало $\\tanh(x_{ij})$ - тоже число.\n",
    "Для чисел есть формула производной сложной функции:\n",
    "$\\cfrac{d(L(\\tanh(x)))}{dx} = \\underbrace{\\cfrac{d(L(t)) |_{t=\\tanh(x)}}{dt}}_\\text{градиент по выходу} \\cdot \\cfrac{d(\\tanh x)}{dx}$\n",
    "\n",
    "Т.е. градиент по входу - это градиент по выходу, умноженный покоординатно на $(\\tanh x_{ij})'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Реализуйте класс MyTanh в соответствии с комментариями ноутбука.\"\"\"\n",
    "\n",
    "\n",
    "class MyTanh:\n",
    "    def forward(self, x: np.ndarray):\n",
    "        return ...\n",
    "\n",
    "    def get_params(self):\n",
    "        return ()\n",
    "\n",
    "    def backward(\n",
    "        self, output_grad: np.ndarray, layer_input: np.ndarray, layer_output: np.ndarray\n",
    "    ):\n",
    "        grad_by_input = ...\n",
    "        return grad_by_input, []\n",
    "\n",
    "\n",
    "tanh_layer = MyTanh()\n",
    "# ТЕСТЫ\n",
    "# Простой пример: будем решать уравнение tanh(x) = tanh(1)\n",
    "# Очевидно, что x = 1 является решением, но представим, что мы этого не знаем\n",
    "# Будем делать град. спуск из точки 5 - ожидаем придти в точку x = 1\n",
    "expected = np.tanh([1.0])\n",
    "init_ = np.array([5.0])\n",
    "for _ in range(1_000):\n",
    "    grad, _ = tanh_layer.backward(\n",
    "        2 * (tanh_layer.forward(init_) - expected),  # loss от mse\n",
    "        init_,  # вход слоя\n",
    "        None,  # не используется\n",
    "    )\n",
    "    init_ = init_ - 0.2 * grad\n",
    "assert_allclose(init_, 1, rtol=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, у нас есть линейный слой и tanh слой, оба умеют считать градиенты.\n",
    "Соберем теперь back propagation из них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "my_model = [\n",
    "    MyLinearLayerV2(len(x_train.columns), 32),\n",
    "    MyTanh(),\n",
    "    MyLinearLayerV2(32, 1),\n",
    "]\n",
    "\n",
    "\n",
    "def gd_step(model: list, x: np.ndarray, y: np.ndarray):\n",
    "    inputs, outputs = [], []\n",
    "    N = x.shape[0]\n",
    "    # Прогоним все слои, сохраним все промежуточные результаты\n",
    "    for one_layer in model:\n",
    "        inputs.append(x if not outputs else outputs[-1])\n",
    "        result = one_layer.forward(inputs[-1])\n",
    "        outputs.append(result)\n",
    "    # Последний выход уже предсказывает целевую переменную\n",
    "    y_pred = outputs[-1]\n",
    "    assert y_pred.shape == (N, 1)\n",
    "    assert y.shape == (N,)\n",
    "    y_pred = y_pred[:, 0]\n",
    "    # Заметьте, для back propagation не нужно знать само значение MSE\n",
    "    grad_mse = 2 / N * (y_pred - y)\n",
    "    # Чтобы не было проблем с размерностью, сделаем не (N, ), а (N, 1)\n",
    "    grad_current = grad_mse[:, None]\n",
    "    # Теперь все готово к back propagation - идем с конца в начало\n",
    "    for one_layer, one_input, one_output in zip(\n",
    "        model[::-1], inputs[::-1], outputs[::-1]\n",
    "    ):\n",
    "        params = one_layer.get_params()\n",
    "        # Напишите код, который будет:\n",
    "        # - получать градиенты по параметрам\n",
    "        # - обновлять параметры (шаг градиентного спуска, используйте lr)\n",
    "        # - обновляеть градиент предыдущего слоя (переменная grad_current)\n",
    "\n",
    "        # В функции backward() первым всегда возвращается градиент по входу.\n",
    "        # Вторым - список градиентов по параметрам,\n",
    "        # в том же порядке, в котором идут параметры в get_params()\n",
    "\n",
    "        ...\n",
    "\n",
    "    # Подсчитаем MSE, чтобы его залоггировать\n",
    "    mse_loss = 1 / N * ((y_pred - y) ** 2).sum()\n",
    "    return mse_loss\n",
    "\n",
    "\n",
    "gd_step(my_model, x_train.values.astype(np.float32), y_train.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "my_model = [\n",
    "    MyLinearLayerV2(len(x_train.columns), 32),\n",
    "    MyTanh(),\n",
    "    MyLinearLayerV2(32, 1),\n",
    "]\n",
    "losses = []\n",
    "for i in tqdm.trange(num_iter):\n",
    "    losses.append(\n",
    "        gd_step(\n",
    "            my_model,\n",
    "            x_train.values.astype(np.float32),\n",
    "            y_train.values.astype(np.float32),\n",
    "        )\n",
    "    )\n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        plt.plot(losses)\n",
    "        plt.grid()\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"MSE loss\")\n",
    "        plt.show()\n",
    "\n",
    "print(f\"Final losses: {losses[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у вас та же картинка, что была в начале ноутбука, то поздравляем - вы написали градиентный спуск своими руками.\n",
    "\n",
    "А именно:\n",
    "- вы написали линейный и tanh слои и back propagation для них;\n",
    "- потренировали и увидели, что оно работает;\n",
    "- вспомнили все формулы для линейного слоя;\n",
    "\n",
    "Функция gd_step устроена таким образом, что вы можете свою сеть расширять до любого количества слоев. Поэкспериментируйте :)\n",
    "\n",
    "Конечно же, в pytorch поудобнее вышло, чем в нашей реализации.\n",
    "Дело в том, что pytorch делает много \"магии\":\n",
    "- pytorch сам отслеживает все входы и выходы слоев (мы это явно делали в переменных `inputs` и `outputs`)\n",
    "- прячет всю оптимизацию в класс `SGD`\n",
    "- сам строит граф вычислений (в случае сложных сетей)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
