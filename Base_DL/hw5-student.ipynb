{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 5\n",
    "В этом задании мы:\n",
    "\n",
    "1. Построим U-Net для датасета VOC segmentation, посмотрим на качество семантической сегментации.\n",
    "2. Соберем GAN для генерации картинок из MNIST.\n",
    "3. Прикрутим к этому GAN обуславливание на метку класса, посмотрим на результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net на датасете VOC\n",
    "\n",
    "Датасет [Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/) - один из классических датасетов для задачи семантической сегментации.\n",
    "Его используют в статьях и [по сей день](https://paperswithcode.com/dataset/pascal-voc) для бенчмарков.\n",
    "\n",
    "В этом задании вам нужно скачать этот датасет, разбить на train и validation части, и обучить на нем U-Net.\n",
    "Код для U-Net разбирался в семинаре.\n",
    "\n",
    "В ЛМС необходимо сдать вашу реализацию U-Net и `model.pt` файл обученной модели.\n",
    "Чтобы сдать это задание, модель должна достигать accuracy > 50% на тестовом датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as tp\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from IPython.display import clear_output, display\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import VOCSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим датасет\n",
    "import math\n",
    "import requests\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "\n",
    "def download_from_yandex_disk(public_key: str, save_path: str):\n",
    "    base_url = \"https://cloud-api.yandex.net/v1/disk/public/resources/download\"\n",
    "    params = {\"public_key\": public_key}\n",
    "    response = requests.get(base_url, params=params)\n",
    "    response.raise_for_status()\n",
    "    download_url = response.json()[\"href\"]\n",
    "\n",
    "    with requests.get(download_url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            for chunk in tqdm.tqdm(\n",
    "                r.iter_content(chunk_size=8192), total=math.ceil(1950102073 / 8192)\n",
    "            ):\n",
    "                f.write(chunk)\n",
    "\n",
    "\n",
    "DATA_DIR = Path(\"./data\")\n",
    "YANDEX_DISK_LINK = \"https://disk.yandex.ru/d/TynPtWzf6jrMNQ\"\n",
    "ZIP_PATH = \"voc_dataset.zip\"\n",
    "DATA_DIR = Path(\"./data\")\n",
    "\n",
    "if not DATA_DIR.exists():\n",
    "    print(\"Скачиваем...\")\n",
    "    download_from_yandex_disk(YANDEX_DISK_LINK, ZIP_PATH)\n",
    "\n",
    "    print(\"Распаковываем...\")\n",
    "    with zipfile.ZipFile(ZIP_PATH, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(DATA_DIR)\n",
    "\n",
    "    os.remove(ZIP_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для начала загрузим датасет и посмотрим на его структуру\n",
    "dataset = VOCSegmentation(\n",
    "    root=\"./data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"train\",\n",
    "    download=False,\n",
    ")\n",
    "display(dataset[0][0])\n",
    "display(dataset[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В датасете маске присваивается 255 для границы объекта, а внутри объекта присваивается число от 0 до 20 - метка класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пройдемся по всем маскам датасета и возьмем уникальные значения в пикселях\n",
    "reduce(\n",
    "    lambda s1, s2: s1.union(s2),\n",
    "    (set(np.unique(np.array(dataset[i][1])).tolist()) for i in range(len(dataset))),\n",
    "    set(),\n",
    ")\n",
    "# Ага, действительно, метки классов от 0 до 20, при этом 0 означает \"ничего интересного нет\", а 255 означает границу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отрисуем только пиксели со значением 255 и убедимся, что они соответствуют границам объектов\n",
    "plt.imshow(np.where(np.array(dataset[0][1]) == 255, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes, img_size = 22, 256\n",
    "\n",
    "\n",
    "def load_voc_dataset(split: tp.Literal[\"train\", \"val\", \"test\"]):\n",
    "    transforms = A.Compose(\n",
    "        [\n",
    "            A.Resize(img_size, img_size, interpolation=cv2.INTER_NEAREST),\n",
    "            ToTensorV2(),\n",
    "            A.Lambda(\n",
    "                # Нормализуем изображение в отрезок [0, 1]\n",
    "                image=lambda image, **_: image / 255.0,\n",
    "                # Сделайте так, чтобы все классы шли друг от друга с шагом 1 (подумайте, что делать с классом 255)\n",
    "                mask=lambda mask, **_: ...,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    def _transform(image, mask):\n",
    "        # Конвертируем из PIL формата в np.array за счет np.array(image).\n",
    "        # Заметьте, image=..., mask=... - это указание, что есть изображение и что есть маска.\n",
    "        # Albumentations в общем виде по-разному обрабатывает изображения и маски.\n",
    "        transformed = transforms(image=np.array(image), mask=np.array(mask))\n",
    "        return transformed[\"image\"], transformed[\"mask\"]\n",
    "\n",
    "    # Создание датасета с нужными трансформациями\n",
    "    dataset = VOCSegmentation(\n",
    "        root=\"./data\",\n",
    "        year=\"2012\",\n",
    "        image_set=split,\n",
    "        download=not Path(\"./data\").exists(),\n",
    "        transforms=_transform,\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_dataset = load_voc_dataset(\"train\")\n",
    "val_dataset = load_voc_dataset(\"val\")\n",
    "print(train_dataset[0])\n",
    "print(train_dataset[0][0].shape, train_dataset[0][1].shape)\n",
    "\n",
    "# Отрисовка изображения и маски\n",
    "fig, ax = plt.subplots(3, 2, figsize=(9, 9))\n",
    "for i in range(3):\n",
    "    img, mask = train_dataset[i]\n",
    "    ax[i][0].imshow(img.permute(1, 2, 0).numpy())\n",
    "    ax[i][1].imshow(mask.numpy())\n",
    "fig.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь очередь за вами.\n",
    "Обучите модель и сдайте её в ЛМС (инструкции выше).\n",
    "\n",
    "Обратите внимание, что границы объекта выделены пикселем 255 - это немного выбивается из остальных классов, где метки идут с шагом 1 (0, 1, 2 и т.д. до 21).\n",
    "Подумайте, как это исправить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ...\n",
    "torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQKP4sj9kRgg"
   },
   "source": [
    "## GAN на MNIST\n",
    "\n",
    "Во второй части задания мы попробуем генерировать изображения с цифрами.\n",
    "Для этого возьмем модель GAN и обучим ее на датасет MNIST.\n",
    "\n",
    "Ваша задача: скачайте датасет MNIST, обучите на нем GAN, сохраните веса генератора и дискриминатора в `generator.pt` и `discriminator.pt` соответственно.\n",
    "Сдайте в ЛМС:\n",
    "1. Код генератора и его веса.\n",
    "2. Код дискриминатора и его веса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используйте следующие параметры модели\n",
    "image_size = 28\n",
    "# Размер латентного вектора - из него генератор будет создавать изображение\n",
    "nz = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "4YBU5cHMkNxb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN с условиями\n",
    "\n",
    "Наш GAN генерирует картинку из случайного класса.\n",
    "Однако можно научить его принимать на вход метку класса и генерировать картинку с этой меткой.\n",
    "Такие GAN называются **Conditional GAN** (*обусловленный GAN*).\n",
    "\n",
    "Добавить обуславливание достаточно просто:\n",
    "1. Добавьте в генератор embedding-слой для метки класса. Берите небольшую размерность вектора, 10-ти хватит.\n",
    "2. Поменяйте первый ConvTranspose2d так, чтобы тот принял вектор длины 110 (100 от рандома, 10 от эмбеддинга).\n",
    "3. Поменяйте код `forward` так, чтобы в ConvTranspose2d передавать объединенный вектор размера 110.\n",
    "4. Сделайте аналогичные изменения в `Discriminator` - он тоже должен принимать `label` как аргумент в `forward` и учитывать его. Подумайте, какие слои и как надо будет поменять.\n",
    "\n",
    "Сделайте **Conditional GAN**, обучите его.\n",
    "Сдайте в ЛМС:\n",
    "1. Новый код `Generator` и его веса.\n",
    "2. Новый код `Discriminator` и его веса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если вы все сделали правильно, у вас должны получиться правдоподобные картинки для каждого из классов."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}