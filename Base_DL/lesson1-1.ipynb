{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.12"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Знакомство с инструментом PyTorch\n\n## План\nВ этом ноутбуке посмотрим на базовые возможности PyTorch:\n\n0. Подсказки при работе с Jupyter Notebook.\n1. Как создать тензор.\n2. Операции с тензором.\n3. Функции над тензором.\n4. Градиенты в PyTorch.\n5. Функции потерь.\n6. Слои нейросети.\n8. PyTorch и видеокарта.\n\n## Почему именно PyTorch?\nЭтот инструмент стал популярен в мире DL.\nПричин много, но из самых интересных стоит выделить три:\n1. PyTorch имеет numpy-подобный интерфейс, поэтому на него легко перейти после numpy.\n2. PyTorch умеет автоматически считать градиенты всех вычислений, независимо от количества операций.\nМожно учить модели произвольного размера.\n3. В PyTorch уже реализовано много часто используемых в DL операций и слоев нейросетей.\n4. Все вычисления на PyTorch без головной боли можно перенести на GPU и получить прирост x100 в скорости.\n\n## PyTorch: начало\n\nЕсли вы используете Google Colab или Kaggle Notebooks,\nто у вас уже установлен `pytorch`.\nНа 2024-02-10 они оба используют версии 2.1.\n\n<details>\n<summary>**Если используете личный ноутбук или сервер**</summary>\n\nВаш ноутбук или сервер должны иметь видеокарту, и `pytorch` должен \"увидеть\" ее.\n\nСначала устанавливаем пакет `pytorch`.\nЛучше всего это делать в виртуальном окружении (можно и в anaconda).\nВыполняем в терминале команду:\n\n```bash\npip install torch\n```\n\nЗатем открываем интерпретатор Python и выполняем:\n```python\nimport torch\ntorch.cuda.is_avaliable()\n# Должно выдать True\n```\n\nЕсли выдало `True`, то `pytorch` увидел вашу видеокарту и может работать с ней.\nЕсли выдало `False` или ошибку, то рекомендуем прочитать [официальную инструкцию](https://pytorch.org/get-started/locally/) по установке - в ней описано, как установить `pytorch` так, чтобы он \"видел\" видеокарту.\nЕсли же и инструкция не помогла, то советуем работать в Google Colab или Kaggle Notebooks.\n\n</details>","metadata":{}},{"cell_type":"markdown","source":"### Подсказки при работе с Jupyter Notebook","metadata":{}},{"cell_type":"code","source":"import torch\n\ntorch.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:08:40.837311Z","iopub.execute_input":"2026-02-04T05:08:40.837501Z","iopub.status.idle":"2026-02-04T05:08:46.622219Z","shell.execute_reply.started":"2026-02-04T05:08:40.837481Z","shell.execute_reply":"2026-02-04T05:08:46.621351Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7c4ee3bb02f0>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"torch.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:08:52.366577Z","iopub.execute_input":"2026-02-04T05:08:52.367359Z","iopub.status.idle":"2026-02-04T05:08:52.372190Z","shell.execute_reply.started":"2026-02-04T05:08:52.367328Z","shell.execute_reply":"2026-02-04T05:08:52.371360Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'2.8.0+cu126'"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"torch.cuda.is_available()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:08:54.236546Z","iopub.execute_input":"2026-02-04T05:08:54.237140Z","iopub.status.idle":"2026-02-04T05:08:54.288003Z","shell.execute_reply.started":"2026-02-04T05:08:54.237102Z","shell.execute_reply":"2026-02-04T05:08:54.287209Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# torch.sqrt  # Нажмите <Tab>, чтобы увидеть подсказки","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# В Jupyter Notebook можно распечатать документацию к классу или функции\n# Для этого нужно написать в конце \"?\"\ntorch.Tensor?","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0;31mInit signature:\u001b[0m torch.Tensor(*args, **kwargs)\n","\u001b[0;31mDocstring:\u001b[0m      <no docstring>\n","\u001b[0;31mFile:\u001b[0m           /usr/local/lib/python3.12/dist-packages/torch/__init__.py\n","\u001b[0;31mType:\u001b[0m           _TensorMeta\n","\u001b[0;31mSubclasses:\u001b[0m     SparseSemiStructuredTensor, Parameter, Buffer, UninitializedBuffer, NestedTensor, FakeTensor, FunctionalTensor, LoggingTensor, MaskedTensor\n"]}],"execution_count":3},{"cell_type":"code","source":"# Можно также распечатать весь исходный код, дописав в конец \"??\"\ntorch.nn.functional.mse_loss??","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0;31mSignature:\u001b[0m torch.nn.functional.mse_loss(input: torch.Tensor, target: torch.Tensor, size_average: Optional[bool] = None, reduce: Optional[bool] = None, reduction: str = 'mean', weight: Optional[torch.Tensor] = None) -> torch.Tensor\n","\u001b[0;31mSource:\u001b[0m   \n","def mse_loss(\n","    input: Tensor,\n","    target: Tensor,\n","    size_average: Optional[bool] = None,\n","    reduce: Optional[bool] = None,\n","    reduction: str = \"mean\",\n","    weight: Optional[Tensor] = None,\n",") -> Tensor:\n","    r\"\"\"Compute the element-wise mean squared error, with optional weighting.\n","\n","    See :class:`~torch.nn.MSELoss` for details.\n","\n","    Args:\n","        input (Tensor): Predicted values.\n","        target (Tensor): Ground truth values.\n","        size_average (bool, optional): Deprecated (see :attr:`reduction`).\n","        reduce (bool, optional): Deprecated (see :attr:`reduction`).\n","        reduction (str, optional): Specifies the reduction to apply to the output:\n","                                   'none' | 'mean' | 'sum'. 'mean': the mean of the output is taken.\n","                                   'sum': the output will be summed. 'none': no reduction will be applied.\n","                                   Default: 'mean'.\n","        weight (Tensor, optional): Weights for each sample. Default: None.\n","\n","    Returns:\n","        Tensor: Mean Squared Error loss (optionally weighted).\n","    \"\"\"\n","    if has_torch_function_variadic(input, target, weight):\n","        return handle_torch_function(\n","            mse_loss,\n","            (input, target, weight),\n","            input,\n","            target,\n","            size_average=size_average,\n","            reduce=reduce,\n","            reduction=reduction,\n","            weight=weight,\n","        )\n","\n","    if not (target.size() == input.size()):\n","        warnings.warn(\n","            f\"Using a target size ({target.size()}) that is different to the input size ({input.size()}). \"\n","            \"This will likely lead to incorrect results due to broadcasting. \"\n","            \"Please ensure they have the same size.\",\n","            stacklevel=2,\n","        )\n","\n","    if size_average is not None or reduce is not None:\n","        reduction = _Reduction.legacy_get_string(size_average, reduce)\n","\n","    expanded_input, expanded_target = torch.broadcast_tensors(input, target)\n","\n","    if weight is not None:\n","        if weight.size() != input.size():\n","            raise ValueError(\"Weights and input must have the same size.\")\n","\n","        # Perform weighted MSE loss manually\n","        squared_errors = torch.pow(expanded_input - expanded_target, 2)\n","        weighted_squared_errors = squared_errors * weight\n","\n","        if reduction == \"none\":\n","            return weighted_squared_errors\n","        elif reduction == \"sum\":\n","            return torch.sum(weighted_squared_errors)\n","        elif reduction == \"mean\":\n","            return torch.sum(weighted_squared_errors) / torch.sum(weight)\n","        else:\n","            raise ValueError(\n","                f\"Invalid reduction mode: {reduction}. Expected one of 'none', 'mean', 'sum'.\"\n","            )\n","    else:\n","        return torch._C._nn.mse_loss(\n","            expanded_input, expanded_target, _Reduction.get_enum(reduction)\n","        )\n","\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\n","\u001b[0;31mType:\u001b[0m      function\n"]}],"execution_count":4},{"cell_type":"markdown","source":"### Тензор: великий и ужасный\n\nНапомним: тензор — это всего лишь набор чисел, расфасованных по осям.\nО тензоре можно думать как о матрице — вот только если матрица была двумерна, то тензор может иметь три и более размерности.\n\nТензор с размерностью 1 — это вектор, список чисел.\n\nТензор с размерностью 2 — это матрица, то есть список списков чисел.\n\nТензор с размерностью 3 и больше — это тензор, то есть список списков списков (и т.д.) чисел.\n\n\n![meme](./meme.png)\n\n#### Как создать тензор\nНаучимся создавать:\n1. Тензор с непредсказуемыми данными (самый простой вариант).\n2. Тензор из нулей.\n3. Тензор, заполненный одним и тем же числом.\n4. Тензор со значениями из нормального распределения.\n\nТакже познакомимся с in-place операциями и тем, как с ними не запутаться.","metadata":{}},{"cell_type":"code","source":"\"\"\"\nЕсть много способов создать тензор в torch.\nПосмотрим на некоторые из них.\n\"\"\"\n\n# Самый простой — запросить тензор определенной размерности\n\nt = torch.Tensor(2, 3, 4)\n# Будет заполнен произвольными непредсказуемыми данными\nt","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[1.5766e-19, 1.0256e-08, 1.0255e-08, 3.0784e+12],\n","         [4.3354e-08, 2.6260e-06, 1.7471e-04, 1.2610e+16],\n","         [2.1707e-18, 7.0952e+22, 1.7748e+28, 1.8176e+31]],\n","\n","        [[7.2708e+31, 5.0778e+31, 3.2608e-12, 1.7728e+28],\n","         [7.0367e+22, 2.1715e-18, 1.3108e-08, 2.7179e+23],\n","         [8.4272e-07, 1.7183e-04, 1.6520e-04, 1.3040e-11]]])"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"execution_count":5},{"cell_type":"code","source":"# Можно спросить, какой размер. Помним, что было (2, 3, 4)\nt.size()","metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([2, 3, 4])"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"execution_count":6},{"cell_type":"code","source":"# Есть .shape — работает аналогично\nt.shape","metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([2, 3, 4])"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"execution_count":7},{"cell_type":"code","source":"# shape можно удобно сравнивать с tuple — пригодится в тестах\nassert t.shape == (2, 3, 4)","metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# В torch много функций для самых \"ходовых\" тензоров.\n# Например, создать тензор из нулей\n# Сделаем матрицу (5, 3), заполненную нулями\ntorch.zeros((5, 3))","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.],\n","        [0., 0., 0.]])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"execution_count":11},{"cell_type":"code","source":"# Тензор (2, 3, 4), все числа равны 1.\n# Обратите внимание на точку после 1. — это значит, что тип float\nt = torch.ones((2, 3, 4), dtype=torch.float16)\nt","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]],\n","\n","        [[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]]], dtype=torch.float16)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"execution_count":14},{"cell_type":"code","source":"# Тензор (2, 3, 4), все числа равны 1.\n# Обратите внимание на точку после 1. — это значит, что тип float\nt = torch.ones((2, 3, 4))\nt","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]],\n","\n","        [[1., 1., 1., 1.],\n","         [1., 1., 1., 1.],\n","         [1., 1., 1., 1.]]])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"execution_count":15},{"cell_type":"code","source":"# А если точнее — float32.\n# На лекции мы знакомились с fp16, fp32 — это оно и есть.\nt.dtype","metadata":{},"outputs":[{"data":{"text/plain":["torch.float32"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"execution_count":16},{"cell_type":"code","source":"# аналогично можно заполнить любыми числами:\n2.7 * torch.ones((3, 2, 4))","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[2.7000, 2.7000, 2.7000, 2.7000],\n","         [2.7000, 2.7000, 2.7000, 2.7000]],\n","\n","        [[2.7000, 2.7000, 2.7000, 2.7000],\n","         [2.7000, 2.7000, 2.7000, 2.7000]],\n","\n","        [[2.7000, 2.7000, 2.7000, 2.7000],\n","         [2.7000, 2.7000, 2.7000, 2.7000]]])"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"execution_count":17},{"cell_type":"markdown","source":"Обратите внимание на квадратные скобки.\nПо ним видно, что тензор как будто состоит из двух матриц 3x4, соединенных вместе.","metadata":{}},{"cell_type":"code","source":"# Тензор (2, 3, 2, 4), каждый элемент взят из стандартного нормального распределения\ntorch.randn((2, 3, 2, 4))","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[[[ 1.9269,  1.4873,  0.9007, -2.1055],\n","          [ 0.6784, -1.2345, -0.0431, -1.6047]],\n","\n","         [[-0.7521,  1.6487, -0.3925, -1.4036],\n","          [-0.7279, -0.5594, -0.7688,  0.7624]],\n","\n","         [[ 1.6423, -0.1596, -0.4974,  0.4396],\n","          [-0.7581,  1.0783,  0.8008,  1.6806]]],\n","\n","\n","        [[[ 1.2791,  1.2964,  0.6105,  1.3347],\n","          [-0.2316,  0.0418, -0.2516,  0.8599]],\n","\n","         [[-1.3847, -0.8712, -0.2234,  1.7174],\n","          [ 0.3189, -0.4245,  0.3057, -0.7746]],\n","\n","         [[-1.5576,  0.9956, -0.8798, -0.6011],\n","          [-1.2742,  2.1228, -1.2347, -0.4879]]]])"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"execution_count":18},{"cell_type":"markdown","source":"##### in-place операции\nВсе рассмотренные выше операции создают **новый** тензор.\nНо иногда хочется не создавать новый, а менять существующий.\n\nДля этого есть т.н. \"in-place\" (\"на месте\") операции — они меняют тот тензор,\nнад которым применяются, и не создают никаких других тензоров.","metadata":{}},{"cell_type":"code","source":"# Создадим тензор из единиц\nt = torch.ones((2, 3))\nt","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[1., 1., 1.],\n","        [1., 1., 1.]])"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"execution_count":19},{"cell_type":"code","source":"# И занулим его. Обратите внимание на нижнее подчеркивание.\nt.zero_()\nt","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[0., 0., 0.],\n","        [0., 0., 0.]])"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"execution_count":20},{"cell_type":"markdown","source":"В torch все in-place операции строятся как обычные с нижним подчеркиванием (`_`) в конце.","metadata":{}},{"cell_type":"code","source":"print(t)\nt.random_()\nprint(t)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[12648521.,  3275686.,    84453.],\n","        [ 5147423.,  1954303., 15271690.]])\n","tensor([[10804659., 11863032., 11041448.],\n","        [ 8242561., 14953591.,  2428168.]])\n"]}],"execution_count":22},{"cell_type":"markdown","source":"In-place операции позволяют сэкономить память, т.к. создаем в два раза меньше тензоров.\nУ этого есть обратная сторона: если мы передаем тензор в функцию, то функция может\nэтот тензор \"испортить\", поменяв его in-place.\n\nПосмотрим на примере:","metadata":{}},{"cell_type":"code","source":"def random_like(a: torch.Tensor) -> torch.Tensor:\n    \"\"\"Создать случайный тензор того же размера, что и `a`.\"\"\"\n    # перезатираем `a` - это не очень хорошо\n    return a.random_(0, 5)\n\n\nzero_tensor = torch.zeros((2, 3))\nprint(\"zero_tensor до функции:\")\nprint(zero_tensor)\n\nrandom_tensor = random_like(zero_tensor)\nprint(\"Рандомный тензор того же размера:\")\nprint(random_tensor)\n\nprint(\"zero_tensor после функции:\")\nprint(zero_tensor)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["zero_tensor до функции:\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n","Рандомный тензор того же размера:\n","tensor([[1., 0., 0.],\n","        [0., 0., 1.]])\n","zero_tensor после функции:\n","tensor([[1., 0., 0.],\n","        [0., 0., 1.]])\n"]}],"execution_count":23},{"cell_type":"code","source":"# без перезатирания\ndef random_like(a: torch.Tensor) -> torch.Tensor:\n    return torch.randint(0, 5, a.shape, dtype=torch.float32)\n    # еще можно одной строкой\n    # return torch.randint_like(a, 0, 5)\n    # у многих функций есть _like аналоги: zero_like, ones_like\n\n\nzero_tensor = torch.zeros((2, 3))\nprint(\"zero_tensor до функции:\")\nprint(zero_tensor)\n\nrandom_tensor = random_like(zero_tensor)\nprint(\"Рандомный тензор того же размера:\")\nprint(random_tensor)\n\nprint(\"zero_tensor после функции:\")\nprint(zero_tensor)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["zero_tensor до функции:\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n","Рандомный тензор того же размера:\n","tensor([[3., 0., 1.],\n","        [1., 2., 4.]])\n","zero_tensor после функции:\n","tensor([[0., 0., 0.],\n","        [0., 0., 0.]])\n"]}],"execution_count":24},{"cell_type":"markdown","source":"#### Операции с тензором\nТензор создали, что же с ним можно делать дальше?\nМного чего. Мы рассмотрим несколько типов операций:\n1. Бинарные — как два тензора могут взаимодействовать.\n2. Индексирование — как нарезать тензор на куски.\n3. Продвинутое создание и индексирование — закрепим знания.\n\nПервая причина популярности PyTorch: numpy-подобный интерфейс, к которому быстро привыкаешь.\nПосмотрим, что нам предлагает этот инструмент.\n##### Бинарные операции\nТензоры в PyTorch умеют делать те же операции, что и в NumPy: сложение, умножение, возведение в степень и т.д.\nПосмотрим на некоторые из них.","metadata":{}},{"cell_type":"code","source":"# Тензоры одинаковой размерности можно сложить\n2 * torch.ones((2, 3)) + 3 * torch.ones((2, 3))","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[5., 5., 5.],\n","        [5., 5., 5.]])"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"execution_count":25},{"cell_type":"code","source":"# Можно умножать поэлементно\na = torch.eye(3)\nprint(a)\nb = torch.randint_like(a, 2, 4)\nprint(b)\nprint(a * b)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1., 0., 0.],\n","        [0., 1., 0.],\n","        [0., 0., 1.]])\n","tensor([[2., 3., 2.],\n","        [3., 3., 3.],\n","        [2., 3., 2.]])\n","tensor([[2., 0., 0.],\n","        [0., 3., 0.],\n","        [0., 0., 2.]])\n"]}],"execution_count":26},{"cell_type":"code","source":"# Можно умножить матричным умножением\n# Обратите внимание на torch.tensor с маленькой буквы — так можно создавать тензор из списка.\n# каждая вложенность списка — это новая размерность тензора.\na = torch.tensor([[3, 5]])\nprint(a)\nprint(a.shape)\nb = torch.tensor(\n    [\n        [2, 4],\n        [4, 2],\n    ]\n)\nprint(b)\n\"\"\"\n         2 | 4\n[3, 5] *   |    = [3*2 + 5*4, 3*4 + 5*2]\n         4 | 2\n\"\"\"\n# оператор @\nprint(a @ b)\nprint(torch.matmul(a,b))","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[3, 5]])\n","torch.Size([1, 2])\n","tensor([[2, 4],\n","        [4, 2]])\n","tensor([[26, 22]])\n","tensor([[26, 22]])\n"]}],"execution_count":28},{"cell_type":"code","source":"# Оператор @ также делает скалярное умножение векторов.\n# Результат тоже будет тензором - нуль-мерным тензором.\n# Чтобы превратить его в число, используется .item()\np = torch.tensor([3, 4]) @ torch.tensor([5, 6])\nprint(p)\nprint(p.item())","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(39)\n","39\n"]}],"execution_count":29},{"cell_type":"markdown","source":"##### Индексирования\nИндексирование в PyTorch работает так же, как в NumPy — те же квадратные скобки, те же `:`.\nПосмотрим на примеры:","metadata":{}},{"cell_type":"code","source":"a = torch.tensor(\n    [\n        [2, 3],\n        [4, 5],\n        [6, 7],\n    ]\n)\nprint(a)\n# Взять строку с индексом 1 (нумерация идет с нуля)\nprint(a[1])\n# Взять строку с индексом 1, а в ней - то, что по индексу 0\nprint(a[1, 0])\n# Удобнее думать так:\n# - была размерность (3, 2), берем по индексу 1 вдоль первой оси\n# - остается размерность (2,), берем по индексу 0 вдоль первой оси\n# - остается одно число - это 4","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[2, 3],\n","        [4, 5],\n","        [6, 7]])\n","tensor([4, 5])\n","tensor(4)\n"]}],"execution_count":30},{"cell_type":"code","source":"# Можно присваивать через те же [].\n# Чтобы сказать \"все значения\", используем :\na = torch.ones((3, 5, 4, 2))\na[:, 3, :, 1] = 2\nprint(a[:, 3, :, 1])\n# print(a)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[2., 2., 2., 2.],\n","        [2., 2., 2., 2.],\n","        [2., 2., 2., 2.]])\n","tensor([[[[1., 1.],\n","          [1., 1.],\n","          [1., 1.],\n","          [1., 1.]],\n","\n","         [[1., 1.],\n","          [1., 1.],\n","          [1., 1.],\n","          [1., 1.]],\n","\n","         [[1., 1.],\n","          [1., 1.],\n","          [1., 1.],\n","          [1., 1.]],\n","\n","         [[1., 2.],\n","          [1., 2.],\n","          [1., 2.],\n","          [1., 2.]],\n","\n","         [[1., 1.],\n","          [1., 1.],\n","          [1., 1.],\n","          [1., 1.]]],\n","\n","\n","        [[[1., 1.],\n","          [1., 1.],\n","          [1., 1.],\n","          [1., 1.]],\n","\n","         [[1., 1.],\n","          [1., 1.],\n","          [1., 1.],\n","          [1., 1.]],\n","\n","         [[1., 1.],\n","          [1., 1.],\n","          [1., 1.],\n","          [1., 1.]],\n","\n","         [[1., 2.],\n","          [1., 2.],\n","          [1., 2.],\n","          [1., 2.]],\n","\n","         [[1., 1.],\n","          [1., 1.],\n","          [1., 1.],\n","          [1., 1.]]],\n","\n","\n","        [[[1., 1.],\n","          [1., 1.],\n","          [1., 1.],\n","          [1., 1.]],\n","\n","         [[1., 1.],\n","          [1., 1.],\n","          [1., 1.],\n","          [1., 1.]],\n","\n","         [[1., 1.],\n","          [1., 1.],\n","          [1., 1.],\n","          [1., 1.]],\n","\n","         [[1., 2.],\n","          [1., 2.],\n","          [1., 2.],\n","          [1., 2.]],\n","\n","         [[1., 1.],\n","          [1., 1.],\n","          [1., 1.],\n","          [1., 1.]]]])\n"]}],"execution_count":null},{"cell_type":"code","source":"# Можно забирать отрезок из тензора.\n# Левый конец входит, правый не входит.\na = torch.zeros((3, 5))\nprint(a)\na[0:2, 2:4] = 2\nprint(a)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.]])\n","tensor([[0., 0., 2., 2., 0.],\n","        [0., 0., 2., 2., 0.],\n","        [0., 0., 0., 0., 0.]])\n"]}],"execution_count":33},{"cell_type":"markdown","source":"##### Продвинутое создание и индексирование","metadata":{}},{"cell_type":"code","source":"# Тензор с числами в диапазоне.\n# Левая граница входит, правая не входит.\na = torch.arange(2, 9, 2)\nprint(a)\na = torch.arange(2, 9)\nprint(a)\na = torch.arange(10, -4, -2)\nprint(a)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([2, 4, 6, 8])\n","tensor([2, 3, 4, 5, 6, 7, 8])\n","tensor([10,  8,  6,  4,  2,  0, -2])\n"]}],"execution_count":34},{"cell_type":"markdown","source":"В DL часто нужно состыковать размерности на стыке слоев нейросети.\nДля этого приходится добавлять размерность тензору, либо же его \"повернуть на бок\".\n\nПосмотрим, как это делается.","metadata":{}},{"cell_type":"code","source":"a = torch.arange(5)\n# None в индексировании добавляет ось\n# -1 в reshape говорит \"сам угадай, сколько по оси элементов\"\na[:, None] @ torch.tensor([3, 2]).reshape((1, -1))","metadata":{},"outputs":[{"data":{"text/plain":["tensor([[ 0,  0],\n","        [ 3,  2],\n","        [ 6,  4],\n","        [ 9,  6],\n","        [12,  8]])"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"execution_count":35},{"cell_type":"code","source":"# Попробую понять что делается\na = torch.arange(5)\nprint(a[:, None])\nb = torch.tensor([3, 2]) * torch.ones(5, 2)\nprint(b)\nprint(a[:, None] * b)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0],\n","        [1],\n","        [2],\n","        [3],\n","        [4]])\n","tensor([[3., 2.],\n","        [3., 2.],\n","        [3., 2.],\n","        [3., 2.],\n","        [3., 2.]])\n","tensor([[ 0.,  0.],\n","        [ 3.,  2.],\n","        [ 6.,  4.],\n","        [ 9.,  6.],\n","        [12.,  8.]])\n"]}],"execution_count":null},{"cell_type":"code","source":"# Но это не то же самое. Нунжо матричное умножение [5 x 1] matmul [1 x 2] -> [5 x 2]\na = torch.arange(5)\nprint(a[:, None])\nb = torch.tensor([3, 2])\nprint(b[None, :])\nprint(a[:, None] * b[None, :])","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0],\n","        [1],\n","        [2],\n","        [3],\n","        [4]])\n","tensor([[3, 2]])\n","tensor([[ 0,  0],\n","        [ 3,  2],\n","        [ 6,  4],\n","        [ 9,  6],\n","        [12,  8]])\n"]}],"execution_count":49},{"cell_type":"code","source":"a = torch.arange(5 * 5 * 5).reshape((5, 5, 5))\n# При индексировании можно явно указать, какие элементы из какого слоя хотим.\n# Учтите, что \"дырок\" в результате быть не должно\nprint(a[[0, 1, 4], 2:4, [0, 3, 2]])\n# Не сработает, т.к. в последней оси взяли 2 элемента, а в первой 3\n# print(a[[0, 1, 4], 2:4, [0, 1]])","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 10,  15],\n","        [ 38,  43],\n","        [112, 117]])\n"]}],"execution_count":null},{"cell_type":"code","source":"# Возьму поменьше элементов\na = torch.arange(3 * 3 * 3).reshape((3, 3, 3))\nprint(a)\n# При индексировании можно явно указать, какие элементы из какого слоя хотим.\n# print(a[[0, 2], :2, [1, 2]])\nprint(a[:, [0, 2], [0, 2]])\nprint(a[:, [0, 2]][:, :, [0, 2]])\nlayer_idx = [0, 1, 2]\nrow_idx = [0, 2]\ncol_idx = [0, 2]\nprint(a[layer_idx][:, row_idx][:, :, col_idx])\n","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[ 0,  8],\n","        [ 9, 17],\n","        [18, 26]])\n","tensor([[[ 0,  2],\n","         [ 6,  8]],\n","\n","        [[ 9, 11],\n","         [15, 17]],\n","\n","        [[18, 20],\n","         [24, 26]]])\n","tensor([[[ 0,  2],\n","         [ 6,  8]],\n","\n","        [[ 9, 11],\n","         [15, 17]],\n","\n","        [[18, 20],\n","         [24, 26]]])\n"]}],"execution_count":null},{"cell_type":"code","source":"from torch.testing import assert_close\n\n# Матрицу можно транспонировать\na = torch.tensor([[1, 2], [3, 4]])\nprint(a)\nprint(a.T)\n# А если это тензор, то при транспонировании лучше указать две оси\na = torch.arange(27).reshape((3, 3, 3))\nprint(a)\nprint(a.transpose(0, 1))\n\n# a.transpose(0, 1) - это то же самое, что\nresult = torch.zeros_like(a)\nfor i in range(a.shape[2]):\n    result[:, :, i] = a[:, :, i].T\n# assert_close проверяет тензоры на равенство.\nassert_close(result, a.transpose(0, 1))","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2],\n","        [3, 4]])\n","tensor([[1, 3],\n","        [2, 4]])\n","tensor([[[ 0,  1,  2],\n","         [ 3,  4,  5],\n","         [ 6,  7,  8]],\n","\n","        [[ 9, 10, 11],\n","         [12, 13, 14],\n","         [15, 16, 17]],\n","\n","        [[18, 19, 20],\n","         [21, 22, 23],\n","         [24, 25, 26]]])\n","tensor([[[ 0,  1,  2],\n","         [ 9, 10, 11],\n","         [18, 19, 20]],\n","\n","        [[ 3,  4,  5],\n","         [12, 13, 14],\n","         [21, 22, 23]],\n","\n","        [[ 6,  7,  8],\n","         [15, 16, 17],\n","         [24, 25, 26]]])\n"]}],"execution_count":113},{"cell_type":"code","source":"assert_close?","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0;31mSignature:\u001b[0m assert_close(actual: Any, expected: Any, *, allow_subclasses: bool = True, rtol: Optional[float] = None, atol: Optional[float] = None, equal_nan: bool = False, check_device: bool = True, check_dtype: bool = True, check_layout: bool = True, check_stride: bool = False, msg: Union[str, Callable[[str], str], NoneType] = None)\n","\u001b[0;31mDocstring:\u001b[0m\n","Asserts that ``actual`` and ``expected`` are close.\n","\n","If ``actual`` and ``expected`` are strided, non-quantized, real-valued, and finite, they are considered close if\n","\n",".. math::\n","\n","    \\lvert \\text{actual} - \\text{expected} \\rvert \\le \\texttt{atol} + \\texttt{rtol} \\cdot \\lvert \\text{expected} \\rvert\n","\n","Non-finite values (``-inf`` and ``inf``) are only considered close if and only if they are equal. ``NaN``'s are\n","only considered equal to each other if ``equal_nan`` is ``True``.\n","\n","In addition, they are only considered close if they have the same\n","\n","- :attr:`~torch.Tensor.device` (if ``check_device`` is ``True``),\n","- ``dtype`` (if ``check_dtype`` is ``True``),\n","- ``layout`` (if ``check_layout`` is ``True``), and\n","- stride (if ``check_stride`` is ``True``).\n","\n","If either ``actual`` or ``expected`` is a meta tensor, only the attribute checks will be performed.\n","\n","If ``actual`` and ``expected`` are sparse (either having COO, CSR, CSC, BSR, or BSC layout), their strided members are\n","checked individually. Indices, namely ``indices`` for COO, ``crow_indices`` and ``col_indices`` for CSR and BSR,\n","or ``ccol_indices``  and ``row_indices`` for CSC and BSC layouts, respectively,\n","are always checked for equality whereas the values are checked for closeness according to the definition above.\n","\n","If ``actual`` and ``expected`` are quantized, they are considered close if they have the same\n",":meth:`~torch.Tensor.qscheme` and the result of :meth:`~torch.Tensor.dequantize` is close according to the\n","definition above.\n","\n","``actual`` and ``expected`` can be :class:`~torch.Tensor`'s or any tensor-or-scalar-likes from which\n",":class:`torch.Tensor`'s can be constructed with :func:`torch.as_tensor`. Except for Python scalars the input types\n","have to be directly related. In addition, ``actual`` and ``expected`` can be :class:`~collections.abc.Sequence`'s\n","or :class:`~collections.abc.Mapping`'s in which case they are considered close if their structure matches and all\n","their elements are considered close according to the above definition.\n","\n",".. note::\n","\n","    Python scalars are an exception to the type relation requirement, because their :func:`type`, i.e.\n","    :class:`int`, :class:`float`, and :class:`complex`, is equivalent to the ``dtype`` of a tensor-like. Thus,\n","    Python scalars of different types can be checked, but require ``check_dtype=False``.\n","\n","Args:\n","    actual (Any): Actual input.\n","    expected (Any): Expected input.\n","    allow_subclasses (bool): If ``True`` (default) and except for Python scalars, inputs of directly related types\n","        are allowed. Otherwise type equality is required.\n","    rtol (Optional[float]): Relative tolerance. If specified ``atol`` must also be specified. If omitted, default\n","        values based on the :attr:`~torch.Tensor.dtype` are selected with the below table.\n","    atol (Optional[float]): Absolute tolerance. If specified ``rtol`` must also be specified. If omitted, default\n","        values based on the :attr:`~torch.Tensor.dtype` are selected with the below table.\n","    equal_nan (Union[bool, str]): If ``True``, two ``NaN`` values will be considered equal.\n","    check_device (bool): If ``True`` (default), asserts that corresponding tensors are on the same\n","        :attr:`~torch.Tensor.device`. If this check is disabled, tensors on different\n","        :attr:`~torch.Tensor.device`'s are moved to the CPU before being compared.\n","    check_dtype (bool): If ``True`` (default), asserts that corresponding tensors have the same ``dtype``. If this\n","        check is disabled, tensors with different ``dtype``'s are promoted  to a common ``dtype`` (according to\n","        :func:`torch.promote_types`) before being compared.\n","    check_layout (bool): If ``True`` (default), asserts that corresponding tensors have the same ``layout``. If this\n","        check is disabled, tensors with different ``layout``'s are converted to strided tensors before being\n","        compared.\n","    check_stride (bool): If ``True`` and corresponding tensors are strided, asserts that they have the same stride.\n","    msg (Optional[Union[str, Callable[[str], str]]]): Optional error message to use in case a failure occurs during\n","        the comparison. Can also passed as callable in which case it will be called with the generated message and\n","        should return the new message.\n","\n","Raises:\n","    ValueError: If no :class:`torch.Tensor` can be constructed from an input.\n","    ValueError: If only ``rtol`` or ``atol`` is specified.\n","    AssertionError: If corresponding inputs are not Python scalars and are not directly related.\n","    AssertionError: If ``allow_subclasses`` is ``False``, but corresponding inputs are not Python scalars and have\n","        different types.\n","    AssertionError: If the inputs are :class:`~collections.abc.Sequence`'s, but their length does not match.\n","    AssertionError: If the inputs are :class:`~collections.abc.Mapping`'s, but their set of keys do not match.\n","    AssertionError: If corresponding tensors do not have the same :attr:`~torch.Tensor.shape`.\n","    AssertionError: If ``check_layout`` is ``True``, but corresponding tensors do not have the same\n","        :attr:`~torch.Tensor.layout`.\n","    AssertionError: If only one of corresponding tensors is quantized.\n","    AssertionError: If corresponding tensors are quantized, but have different :meth:`~torch.Tensor.qscheme`'s.\n","    AssertionError: If ``check_device`` is ``True``, but corresponding tensors are not on the same\n","        :attr:`~torch.Tensor.device`.\n","    AssertionError: If ``check_dtype`` is ``True``, but corresponding tensors do not have the same ``dtype``.\n","    AssertionError: If ``check_stride`` is ``True``, but corresponding strided tensors do not have the same stride.\n","    AssertionError: If the values of corresponding tensors are not close according to the definition above.\n","\n","The following table displays the default ``rtol`` and ``atol`` for different ``dtype``'s. In case of mismatching\n","``dtype``'s, the maximum of both tolerances is used.\n","\n","+---------------------------+------------+----------+\n","| ``dtype``                 | ``rtol``   | ``atol`` |\n","+===========================+============+==========+\n","| :attr:`~torch.float16`    | ``1e-3``   | ``1e-5`` |\n","+---------------------------+------------+----------+\n","| :attr:`~torch.bfloat16`   | ``1.6e-2`` | ``1e-5`` |\n","+---------------------------+------------+----------+\n","| :attr:`~torch.float32`    | ``1.3e-6`` | ``1e-5`` |\n","+---------------------------+------------+----------+\n","| :attr:`~torch.float64`    | ``1e-7``   | ``1e-7`` |\n","+---------------------------+------------+----------+\n","| :attr:`~torch.complex32`  | ``1e-3``   | ``1e-5`` |\n","+---------------------------+------------+----------+\n","| :attr:`~torch.complex64`  | ``1.3e-6`` | ``1e-5`` |\n","+---------------------------+------------+----------+\n","| :attr:`~torch.complex128` | ``1e-7``   | ``1e-7`` |\n","+---------------------------+------------+----------+\n","| :attr:`~torch.quint8`     | ``1.3e-6`` | ``1e-5`` |\n","+---------------------------+------------+----------+\n","| :attr:`~torch.quint2x4`   | ``1.3e-6`` | ``1e-5`` |\n","+---------------------------+------------+----------+\n","| :attr:`~torch.quint4x2`   | ``1.3e-6`` | ``1e-5`` |\n","+---------------------------+------------+----------+\n","| :attr:`~torch.qint8`      | ``1.3e-6`` | ``1e-5`` |\n","+---------------------------+------------+----------+\n","| :attr:`~torch.qint32`     | ``1.3e-6`` | ``1e-5`` |\n","+---------------------------+------------+----------+\n","| other                     | ``0.0``    | ``0.0``  |\n","+---------------------------+------------+----------+\n","\n",".. note::\n","\n","    :func:`~torch.testing.assert_close` is highly configurable with strict default settings. Users are encouraged\n","    to :func:`~functools.partial` it to fit their use case. For example, if an equality check is needed, one might\n","    define an ``assert_equal`` that uses zero tolerances for every ``dtype`` by default:\n","\n","    >>> import functools\n","    >>> assert_equal = functools.partial(torch.testing.assert_close, rtol=0, atol=0)\n","    >>> assert_equal(1e-9, 1e-10)\n","    Traceback (most recent call last):\n","    ...\n","    AssertionError: Scalars are not equal!\n","    <BLANKLINE>\n","    Expected 1e-10 but got 1e-09.\n","    Absolute difference: 9.000000000000001e-10\n","    Relative difference: 9.0\n","\n","Examples:\n","    >>> # tensor to tensor comparison\n","    >>> expected = torch.tensor([1e0, 1e-1, 1e-2])\n","    >>> actual = torch.acos(torch.cos(expected))\n","    >>> torch.testing.assert_close(actual, expected)\n","\n","    >>> # scalar to scalar comparison\n","    >>> import math\n","    >>> expected = math.sqrt(2.0)\n","    >>> actual = 2.0 / math.sqrt(2.0)\n","    >>> torch.testing.assert_close(actual, expected)\n","\n","    >>> # numpy array to numpy array comparison\n","    >>> import numpy as np\n","    >>> expected = np.array([1e0, 1e-1, 1e-2])\n","    >>> actual = np.arccos(np.cos(expected))\n","    >>> torch.testing.assert_close(actual, expected)\n","\n","    >>> # sequence to sequence comparison\n","    >>> import numpy as np\n","    >>> # The types of the sequences do not have to match. They only have to have the same\n","    >>> # length and their elements have to match.\n","    >>> expected = [torch.tensor([1.0]), 2.0, np.array(3.0)]\n","    >>> actual = tuple(expected)\n","    >>> torch.testing.assert_close(actual, expected)\n","\n","    >>> # mapping to mapping comparison\n","    >>> from collections import OrderedDict\n","    >>> import numpy as np\n","    >>> foo = torch.tensor(1.0)\n","    >>> bar = 2.0\n","    >>> baz = np.array(3.0)\n","    >>> # The types and a possible ordering of mappings do not have to match. They only\n","    >>> # have to have the same set of keys and their elements have to match.\n","    >>> expected = OrderedDict([(\"foo\", foo), (\"bar\", bar), (\"baz\", baz)])\n","    >>> actual = {\"baz\": baz, \"bar\": bar, \"foo\": foo}\n","    >>> torch.testing.assert_close(actual, expected)\n","\n","    >>> expected = torch.tensor([1.0, 2.0, 3.0])\n","    >>> actual = expected.clone()\n","    >>> # By default, directly related instances can be compared\n","    >>> torch.testing.assert_close(torch.nn.Parameter(actual), expected)\n","    >>> # This check can be made more strict with allow_subclasses=False\n","    >>> torch.testing.assert_close(\n","    ...     torch.nn.Parameter(actual), expected, allow_subclasses=False\n","    ... )\n","    Traceback (most recent call last):\n","    ...\n","    TypeError: No comparison pair was able to handle inputs of type\n","    <class 'torch.nn.parameter.Parameter'> and <class 'torch.Tensor'>.\n","    >>> # If the inputs are not directly related, they are never considered close\n","    >>> torch.testing.assert_close(actual.numpy(), expected)\n","    Traceback (most recent call last):\n","    ...\n","    TypeError: No comparison pair was able to handle inputs of type <class 'numpy.ndarray'>\n","    and <class 'torch.Tensor'>.\n","    >>> # Exceptions to these rules are Python scalars. They can be checked regardless of\n","    >>> # their type if check_dtype=False.\n","    >>> torch.testing.assert_close(1.0, 1, check_dtype=False)\n","\n","    >>> # NaN != NaN by default.\n","    >>> expected = torch.tensor(float(\"Nan\"))\n","    >>> actual = expected.clone()\n","    >>> torch.testing.assert_close(actual, expected)\n","    Traceback (most recent call last):\n","    ...\n","    AssertionError: Scalars are not close!\n","    <BLANKLINE>\n","    Expected nan but got nan.\n","    Absolute difference: nan (up to 1e-05 allowed)\n","    Relative difference: nan (up to 1.3e-06 allowed)\n","    >>> torch.testing.assert_close(actual, expected, equal_nan=True)\n","\n","    >>> expected = torch.tensor([1.0, 2.0, 3.0])\n","    >>> actual = torch.tensor([1.0, 4.0, 5.0])\n","    >>> # The default error message can be overwritten.\n","    >>> torch.testing.assert_close(\n","    ...     actual, expected, msg=\"Argh, the tensors are not close!\"\n","    ... )\n","    Traceback (most recent call last):\n","    ...\n","    AssertionError: Argh, the tensors are not close!\n","    >>> # If msg is a callable, it can be used to augment the generated message with\n","    >>> # extra information\n","    >>> torch.testing.assert_close(\n","    ...     actual, expected, msg=lambda msg: f\"Header\\n\\n{msg}\\n\\nFooter\"\n","    ... )\n","    Traceback (most recent call last):\n","    ...\n","    AssertionError: Header\n","    <BLANKLINE>\n","    Tensor-likes are not close!\n","    <BLANKLINE>\n","    Mismatched elements: 2 / 3 (66.7%)\n","    Greatest absolute difference: 2.0 at index (1,) (up to 1e-05 allowed)\n","    Greatest relative difference: 1.0 at index (1,) (up to 1.3e-06 allowed)\n","    <BLANKLINE>\n","    Footer\n","\u001b[0;31mFile:\u001b[0m      /usr/local/lib/python3.12/dist-packages/torch/testing/_comparison.py\n","\u001b[0;31mType:\u001b[0m      function\n"]}],"execution_count":114},{"cell_type":"code","source":"torch.transpose?","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0;31mDocstring:\u001b[0m\n","transpose(input, dim0, dim1) -> Tensor\n","\n","Returns a tensor that is a transposed version of :attr:`input`.\n","The given dimensions :attr:`dim0` and :attr:`dim1` are swapped.\n","\n","If :attr:`input` is a strided tensor then the resulting :attr:`out`\n","tensor shares its underlying storage with the :attr:`input` tensor, so\n","changing the content of one would change the content of the other.\n","\n","If :attr:`input` is a :ref:`sparse tensor <sparse-docs>` then the\n","resulting :attr:`out` tensor *does not* share the underlying storage\n","with the :attr:`input` tensor.\n","\n","If :attr:`input` is a :ref:`sparse tensor <sparse-docs>` with compressed\n","layout (SparseCSR, SparseBSR, SparseCSC or SparseBSC) the arguments\n",":attr:`dim0` and :attr:`dim1` must be both batch dimensions, or must\n","both be sparse dimensions. The batch dimensions of a sparse tensor are the\n","dimensions preceding the sparse dimensions.\n","\n",".. note::\n","    Transpositions which interchange the sparse dimensions of a `SparseCSR`\n","    or `SparseCSC` layout tensor will result in the layout changing between\n","    the two options. Transposition of the sparse dimensions of a ` SparseBSR`\n","    or `SparseBSC` layout tensor will likewise generate a result with the\n","    opposite layout.\n","\n","\n","Args:\n","    input (Tensor): the input tensor.\n","    dim0 (int): the first dimension to be transposed\n","    dim1 (int): the second dimension to be transposed\n","\n","Example::\n","\n","    >>> x = torch.randn(2, 3)\n","    >>> x\n","    tensor([[ 1.0028, -0.9893,  0.5809],\n","            [-0.1669,  0.7299,  0.4942]])\n","    >>> torch.transpose(x, 0, 1)\n","    tensor([[ 1.0028, -0.1669],\n","            [-0.9893,  0.7299],\n","            [ 0.5809,  0.4942]])\n","\n","See also :func:`torch.t`.\n","\u001b[0;31mType:\u001b[0m      builtin_function_or_method\n"]}],"execution_count":107},{"cell_type":"markdown","source":"#### Функции над тензором\nБольшинство функций, которые есть в NumPy над матрицами,\nесть и в PyTorch над тензорами.\nРассмотрим самые популярные из этих функций:\n- сложение, умножение, вычитание, деление;\n- матричное умножение;\n- обращение тензора;\n\nТакже разберем нетривиальные моменты.","metadata":{}},{"cell_type":"code","source":"# Тензоры можно возводить в степень, умножать друг на друга.\n# Это будет поэлементно!\n# Вообще, большинство арифметических операций в pytorch выполняются поэлементно.\n# Это +, -, *, /\na = torch.arange(4).reshape((2, 2))\nb = torch.arange(4, 8).reshape((2, 2))\nprint(\"Поэлементное умножение:\")\nprint(a * b)\nprint(\"То же самое, что '*':\")\nprint(a.mul(b))\nprint('То же самое, что \"+\", есть inplace-версия a.add_(b):')\nprint(a.add(b))\nprint(\"Возвести в квадрат поэлементно:\")\nprint(a**2)\nprint(\"Обратите внимание: в математической литературе A^2 - это не поэлементно\")\nprint(\"В матем. литературе обычно под A^2 подразумевают следующее:\")\nprint(a @ a)\nprint(\"В частности, обратную матрицу надо считать вот так:\")\nprint(a.float().inverse())  # приводим к float, т.к. inverse работает только с ним\nprint(\"Но вот a**(-1) лишь каждый элемент обратит:\")\nprint(a.float() ** (-1))  # pytorch не дает обращать integer элементы тензора","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:08:47.146227Z","iopub.execute_input":"2026-02-04T04:08:47.146592Z","iopub.status.idle":"2026-02-04T04:08:47.271328Z","shell.execute_reply.started":"2026-02-04T04:08:47.146563Z","shell.execute_reply":"2026-02-04T04:08:47.270182Z"}},"outputs":[{"name":"stdout","text":"Поэлементное умножение:\ntensor([[ 0,  5],\n        [12, 21]])\nТо же самое, что '*':\ntensor([[ 0,  5],\n        [12, 21]])\nТо же самое, что \"+\", есть inplace-версия a.add_(b):\ntensor([[ 4,  6],\n        [ 8, 10]])\nВозвести в квадрат поэлементно:\ntensor([[0, 1],\n        [4, 9]])\nОбратите внимание: в математической литературе A^2 - это не поэлементно\nВ матем. литературе обычно под A^2 подразумевают следующее:\ntensor([[ 2,  3],\n        [ 6, 11]])\nВ частности, обратную матрицу надо считать вот так:\ntensor([[-1.5000,  0.5000],\n        [ 1.0000,  0.0000]])\nНо вот a**(-1) лишь каждый элемент обратит:\ntensor([[   inf, 1.0000],\n        [0.5000, 0.3333]])\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"## Градиенты в PyTorch\nВторая причина популярности PyTorch: удобная работа с производными операций.\n\nPyTorch умеет считать градиенты автоматически.\nВы делаете любое вычисление, например:\n```python\nresult = my_matrix ** 2\n# затем\nresult.backward()\n```\nБолее подробная [документация](https://pytorch.org/docs/stable/notes/autograd.html).","metadata":{}},{"cell_type":"code","source":"# requires_grad=True означает, что мы хотим считать градиент по всем элементам тензора\nw = torch.tensor([[1, 1], [2, 2]], dtype=float, requires_grad=True)\nx = torch.tensor([[5], [3]], dtype=float)\nprint(w)\nprint(w.grad)\nfinal_answer = w @ x\nprint(final_answer)\none_scalar = final_answer.sum()\none_scalar.backward()\nprint(w.grad)\n# градиент можно брать только от скаляров, следующая строка не сработает:\n# final_answer.backward()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:13:30.924693Z","iopub.execute_input":"2026-02-04T04:13:30.925657Z","iopub.status.idle":"2026-02-04T04:13:30.934997Z","shell.execute_reply.started":"2026-02-04T04:13:30.925620Z","shell.execute_reply":"2026-02-04T04:13:30.933970Z"}},"outputs":[{"name":"stdout","text":"tensor([[1., 1.],\n        [2., 2.]], dtype=torch.float64, requires_grad=True)\nNone\ntensor([[ 8.],\n        [16.]], dtype=torch.float64, grad_fn=<MmBackward0>)\ntensor([[5., 3.],\n        [5., 3.]], dtype=torch.float64)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"А теперь вручную считаем:\n$$\n    \\begin{bmatrix}\n        w_{11} & w_{12} \\\\\n        w_{21} & w_{22}\n    \\end{bmatrix}\n    \\begin{bmatrix}\n        x_1 \\\\\n        x_2\n    \\end{bmatrix}\n    = \\begin{bmatrix}\n        w_{11} x_1 + w_{12} x_2 \\\\\n        w_{21} x_1 + w_{22} x_2\n    \\end{bmatrix}\n    \\xrightarrow{\\sum}\n    w_{11} x_1 + w_{12} x_2 + w_{21} x_1 + w_{22} x_2\n$$\nотсюда видим, что\n$$\n\\frac{\\partial L}{\\partial w_{11}} = x_1; \\quad \n\\frac{\\partial L}{\\partial w_{12}} = x_2; \\quad \n\\frac{\\partial L}{\\partial w_{21}} = x_1; \\quad \n\\frac{\\partial L}{\\partial w_{22}} = x_2; \\quad \n$$\nСмотрим на числа выше и убеждаемся, что градиент был подсчитан верно.","metadata":{}},{"cell_type":"code","source":"# Градиент не будет работать без requires_grad=True\na = torch.tensor([1.0, 2.0])\ntry:\n    torch.sum(a).backward()\nexcept RuntimeError as e:\n    print(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:15:59.600535Z","iopub.execute_input":"2026-02-04T04:15:59.601450Z","iopub.status.idle":"2026-02-04T04:15:59.618147Z","shell.execute_reply.started":"2026-02-04T04:15:59.601405Z","shell.execute_reply":"2026-02-04T04:15:59.616937Z"}},"outputs":[{"name":"stdout","text":"element 0 of tensors does not require grad and does not have a grad_fn\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Чтобы суметь подсчитать градиент,\n# pytorch сохраняет все промежуточные результаты.\n# Иногда не нужно считать градиент (даже если requires_grad=True)\n# В таком случае можно попросить не хранить эти промежуточные результаты.\n# Это экономит память.\na = torch.tensor([1.0, 0.2], requires_grad=True)\nb = a.sum()\nc = b ** 2\nc.backward()\nprint(b.grad)\nprint()\nprint(a.grad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:17:40.091932Z","iopub.execute_input":"2026-02-04T04:17:40.092291Z","iopub.status.idle":"2026-02-04T04:17:40.100982Z","shell.execute_reply.started":"2026-02-04T04:17:40.092262Z","shell.execute_reply":"2026-02-04T04:17:40.100024Z"}},"outputs":[{"name":"stdout","text":"None\n\ntensor([2.4000, 2.4000])\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/607681094.py:10: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at /pytorch/build/aten/src/ATen/core/TensorBody.h:489.)\n  print(b.grad)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# Чтобы суметь подсчитать градиент,\n# pytorch сохраняет все промежуточные результаты.\n# Иногда не нужно считать градиент (даже если requires_grad=True)\n# В таком случае можно попросить не хранить эти промежуточные результаты.\n# Это экономит память.\na = torch.tensor([1.0, 0.2], requires_grad=True)\nb = a.sum()\nb.retain_grad()  # for non-leaf tensors!\nc = b ** 2\nc.backward()\nprint(b.grad)\nprint()\nprint(a.grad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:27:40.407785Z","iopub.execute_input":"2026-02-04T04:27:40.408134Z","iopub.status.idle":"2026-02-04T04:27:40.418571Z","shell.execute_reply.started":"2026-02-04T04:27:40.408103Z","shell.execute_reply":"2026-02-04T04:27:40.417552Z"}},"outputs":[{"name":"stdout","text":"tensor(2.4000)\n\ntensor([2.4000, 2.4000])\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"with torch.no_grad():\n    b = a.sum()\n# уже не сработает - градиента не было\ntry:\n    b.backward()\nexcept RuntimeError as e:\n    print(e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:22:15.972282Z","iopub.execute_input":"2026-02-04T04:22:15.972651Z","iopub.status.idle":"2026-02-04T04:22:15.980112Z","shell.execute_reply.started":"2026-02-04T04:22:15.972623Z","shell.execute_reply":"2026-02-04T04:22:15.979257Z"}},"outputs":[{"name":"stdout","text":"element 0 of tensors does not require grad and does not have a grad_fn\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Если тензор участвует в нескольких вычислениях, то вызов .backwards() сложит градиенты\nw = torch.tensor([1.0, 2.0], requires_grad=True)\nx = torch.tensor([3.0, 4.0])\n# Производная loss_1 даст 2w*x = [6, 16]\nloss_1 = torch.sum(w**2 * x)\n# Производная loss_2 даст 2w + x = [2 + 3, 4 + 4] = [5, 8]\nloss_2 = torch.sum(w**2 + w * x + 2)\nprint(w.grad)\nloss_1.backward()\nprint(w.grad)\nloss_2.backward()\n# Две производные сложились: [6, 16] + [5, 8] = [11, 24]\nprint(w.grad)","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["None\n","tensor([ 6., 16.])\n","tensor([11., 24.])\n"]}],"execution_count":35},{"cell_type":"markdown","source":"### Функции потерь\nВ обычном ML было много функций потерь: MSE, MAE, MAPE и так далее.\nОни есть и pytorch.","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\n# (5 - 2)^2 = 9\nloss = F.mse_loss(torch.tensor([2.0]), torch.tensor([5.0]))\nprint(loss)\n# mean(|2 - 5| + |4 - 0|) = mean(3, 4) = 3.5\nloss = F.l1_loss(torch.tensor([2.0, 4.0]), torch.tensor([5.0, 0.0]))\nprint(loss)\n# можно не усреднять, а суммировать\nloss = F.l1_loss(torch.tensor([2.0, 4.0]), torch.tensor([5.0, 0.0]), reduction=\"sum\")\nprint(loss)\n\n# От них можно так же брать градиент!\nw = torch.tensor([1.0, 2.0], requires_grad=True)\nx = torch.tensor([1.0, 1.0])\ny_true = torch.tensor(5.0)\ny_pred = w @ x\nloss = F.mse_loss(y_pred, y_true)\nloss.backward()\nprint(\"Градиент (y_true - w @ x)^2:\")\nprint(w.grad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:43:42.564697Z","iopub.execute_input":"2026-02-04T04:43:42.565561Z","iopub.status.idle":"2026-02-04T04:43:42.578337Z","shell.execute_reply.started":"2026-02-04T04:43:42.565521Z","shell.execute_reply":"2026-02-04T04:43:42.577148Z"}},"outputs":[{"name":"stdout","text":"tensor(9.)\ntensor(3.5000)\ntensor(7.)\nГрадиент (y_true - w @ x)^2:\ntensor([-4., -4.])\n","output_type":"stream"}],"execution_count":20},{"cell_type":"markdown","source":"## Слои нейросети\nНа лекции мы узнали, что нейросети строятся из слоев.\nЕсть ли слои в pytorch?\n\nДа, они есть — их много готовых.\nЭто третья причина популярности PyTorch: многие слои из мира Deep Learning уже реализованы и готовы к использованию.\n\nВ этом ноутбуке мы рассмотрим полносвязный слой, с остальными будем знакомиться в следующих уроках.","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\n\n# Слой вида y = w @ x + b\n# Веса инициализируются случайными числами\n# bias=False означает \"b=0 всегда\"\nlin_1 = nn.Linear(2, 1)\n# Принимает тензор размерности (bs, in_features)\n# bs - batch_size, размер батча\n# in_features - размерность каждого вектора, в нашем случае 2\ny = lin_1(torch.ones((6, 2)))\nprint(y)\ny.retain_grad()\nf = y.sum()\nf.backward()\nprint(y.grad)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:19:31.028087Z","iopub.execute_input":"2026-02-04T05:19:31.028734Z","iopub.status.idle":"2026-02-04T05:19:31.128384Z","shell.execute_reply.started":"2026-02-04T05:19:31.028708Z","shell.execute_reply":"2026-02-04T05:19:31.127673Z"}},"outputs":[{"name":"stdout","text":"tensor([[0.9619],\n        [0.9619],\n        [0.9619],\n        [0.9619],\n        [0.9619],\n        [0.9619]], grad_fn=<AddmmBackward0>)\ntensor([[1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.]])\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"nn.Linear?","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:19:31.394773Z","iopub.execute_input":"2026-02-04T05:19:31.395056Z","iopub.status.idle":"2026-02-04T05:19:31.435596Z","shell.execute_reply.started":"2026-02-04T05:19:31.395033Z","shell.execute_reply":"2026-02-04T05:19:31.434877Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[0;31mInit signature:\u001b[0m\n\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0min_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mout_features\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;31mDocstring:\u001b[0m     \nApplies an affine linear transformation to the incoming data: :math:`y = xA^T + b`.\n\nThis module supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nOn certain ROCm devices, when using float16 inputs this module will use :ref:`different precision<fp16_on_mi200>` for backward.\n\nArgs:\n    in_features: size of each input sample\n    out_features: size of each output sample\n    bias: If set to ``False``, the layer will not learn an additive bias.\n        Default: ``True``\n\nShape:\n    - Input: :math:`(*, H_\\text{in})` where :math:`*` means any number of\n      dimensions including none and :math:`H_\\text{in} = \\text{in\\_features}`.\n    - Output: :math:`(*, H_\\text{out})` where all but the last dimension\n      are the same shape as the input and :math:`H_\\text{out} = \\text{out\\_features}`.\n\nAttributes:\n    weight: the learnable weights of the module of shape\n        :math:`(\\text{out\\_features}, \\text{in\\_features})`. The values are\n        initialized from :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})`, where\n        :math:`k = \\frac{1}{\\text{in\\_features}}`\n    bias:   the learnable bias of the module of shape :math:`(\\text{out\\_features})`.\n            If :attr:`bias` is ``True``, the values are initialized from\n            :math:`\\mathcal{U}(-\\sqrt{k}, \\sqrt{k})` where\n            :math:`k = \\frac{1}{\\text{in\\_features}}`\n\nExamples::\n\n    >>> m = nn.Linear(20, 30)\n    >>> input = torch.randn(128, 20)\n    >>> output = m(input)\n    >>> print(output.size())\n    torch.Size([128, 30])\n\u001b[0;31mInit docstring:\u001b[0m Initialize internal Module state, shared by both nn.Module and ScriptModule.\n\u001b[0;31mFile:\u001b[0m           /usr/local/lib/python3.12/dist-packages/torch/nn/modules/linear.py\n\u001b[0;31mType:\u001b[0m           type\n\u001b[0;31mSubclasses:\u001b[0m     NonDynamicallyQuantizableLinear, LazyLinear, Linear, LinearBn1d, Linear\n"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"# У линейного слоя есть веса (weight) и смещение (bias), его можно получить\nprint(lin_1.weight)\nprint()\nprint(lin_1.bias)\nprint()\nlin_2 = nn.Linear(2, 1, bias=False)\n# bias будет None, если его отключить (см. выше)\nprint(lin_2.bias)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:19:34.217867Z","iopub.execute_input":"2026-02-04T05:19:34.218432Z","iopub.status.idle":"2026-02-04T05:19:34.224459Z","shell.execute_reply.started":"2026-02-04T05:19:34.218405Z","shell.execute_reply":"2026-02-04T05:19:34.223798Z"}},"outputs":[{"name":"stdout","text":"Parameter containing:\ntensor([[0.5406, 0.5869]], requires_grad=True)\n\nParameter containing:\ntensor([-0.1657], requires_grad=True)\n\nNone\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Но в лекции говорили, что нужна еще нелинейность.\n# Ее тоже можно найти в torch.nn\nact = nn.Sigmoid()\nprint(act(torch.ones((2, 4))))\nprint()\n# соберем все воедино\n# nn.Sequential позволяет задать несколько слоев подряд\nfc = nn.Sequential(nn.Linear(2, 1, bias=True), nn.Sigmoid())\nprint(fc)\nprint()\nprint(fc(torch.ones((3, 2))))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:19:38.785523Z","iopub.execute_input":"2026-02-04T05:19:38.786247Z","iopub.status.idle":"2026-02-04T05:19:38.802291Z","shell.execute_reply.started":"2026-02-04T05:19:38.786217Z","shell.execute_reply":"2026-02-04T05:19:38.801384Z"}},"outputs":[{"name":"stdout","text":"tensor([[0.7311, 0.7311, 0.7311, 0.7311],\n        [0.7311, 0.7311, 0.7311, 0.7311]])\n\nSequential(\n  (0): Linear(in_features=2, out_features=1, bias=True)\n  (1): Sigmoid()\n)\n\ntensor([[0.5532],\n        [0.5532],\n        [0.5532]], grad_fn=<SigmoidBackward0>)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# В Sequential можно задать имена слоям через OrderedDict\nfrom collections import OrderedDict\n\nfc = nn.Sequential(\n    OrderedDict(\n        [\n            (\"i_am_layer\", nn.Linear(2, 1)),\n            (\"i_am_activation\", nn.Sigmoid()),\n        ]\n    )\n)\nprint(fc)\nprint()\n# слои можно достать по имени (как поле) или по индексу\nprint(fc[0])\nprint()\n# ради такой возможности и заводят слои через OrderedDict\nprint(fc.i_am_layer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:19:39.170617Z","iopub.execute_input":"2026-02-04T05:19:39.170909Z","iopub.status.idle":"2026-02-04T05:19:39.176689Z","shell.execute_reply.started":"2026-02-04T05:19:39.170878Z","shell.execute_reply":"2026-02-04T05:19:39.176004Z"}},"outputs":[{"name":"stdout","text":"Sequential(\n  (i_am_layer): Linear(in_features=2, out_features=1, bias=True)\n  (i_am_activation): Sigmoid()\n)\n\nLinear(in_features=2, out_features=1, bias=True)\n\nLinear(in_features=2, out_features=1, bias=True)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"## PyTorch и видеокарта\nЧетвертая причина популярности PyTorch: удобная работа с видеокартой.\nДавайте посмотрим, как это делается.\n\nС чем мы познакомимся:\n- операции `.to()`, `.cuda()`, `.cpu()` для ускорения вычислений\n- утилита `nvidia-smi` для отслеживания здоровья видеокарты\n- демонстрация скорости — насколько же видеокарта быстрее процессора?\n- какие бывают проблемы с видеокартой и как их решать на примере `device assert triggered`","metadata":{}},{"cell_type":"code","source":"a = torch.tensor([1.0, 3.0])\nprint(a)\n# Каждый тензор лежит либо в RAM (она принадлежит CPU), либо в GPU - это можно узнать по .device\nprint(a.device)\nprint()\n# Тензор легко можно перенести на GPU\na = a.to(\"cuda\")\n# Теперь у нас тензор на GPU.\nprint(a)\nprint(a.device)\nprint()\n# А теперь - обратно на CPU\na = a.to(\"cpu\")\nprint(a)\nprint(a.device)\nprint()\n# Перенести на GPU можно также командой .cuda()\n# Если тензор уже на видеокарте, то .cuda() ничего не будет делать\na = a.cuda()\nprint(a)\nprint(a.device)\nprint()\n# Аналогично можно перенести на CPU через .cpu()\na = a.cpu()\nprint(a)\nprint(a.device)\nprint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:09:17.640227Z","iopub.execute_input":"2026-02-04T05:09:17.640528Z","iopub.status.idle":"2026-02-04T05:09:18.355764Z","shell.execute_reply.started":"2026-02-04T05:09:17.640502Z","shell.execute_reply":"2026-02-04T05:09:18.355030Z"}},"outputs":[{"name":"stdout","text":"tensor([1., 3.])\ncpu\n\ntensor([1., 3.], device='cuda:0')\ncuda:0\n\ntensor([1., 3.])\ncpu\n\ntensor([1., 3.], device='cuda:0')\ncuda:0\n\ntensor([1., 3.])\ncpu\n\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Главное правило - нельзя перемешивать тензоры на видеокарте и тензоры на CPU.\n# Либо все операции на CPU, либо на GPU.\n# Можно какие-то промежуточные значения гонять туда-сюда, но это будет медленно.\n# Так, код ниже не сработает.\ntorch.zeros((2, 3), device=\"cpu\") + torch.zeros((2, 3), device=\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:14:10.254336Z","iopub.execute_input":"2026-02-04T05:14:10.254838Z","iopub.status.idle":"2026-02-04T05:14:10.261445Z","shell.execute_reply.started":"2026-02-04T05:14:10.254810Z","shell.execute_reply":"2026-02-04T05:14:10.260560Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2452876292.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Можно какие-то промежуточные значения гонять туда-сюда, но это будет медленно.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Так, код ниже не сработает.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"],"ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!","output_type":"error"}],"execution_count":9},{"cell_type":"code","source":"# Главное правило - нельзя перемешивать тензоры на видеокарте и тензоры на CPU.\n# Либо все операции на CPU, либо на GPU.\n# Можно какие-то промежуточные значения гонять туда-сюда, но это будет медленно.\n# Так, код ниже не сработает.\ntorch.zeros((2, 3), device=\"cuda:0\") + torch.zeros((2, 3), device=\"cuda\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:14:21.763697Z","iopub.execute_input":"2026-02-04T05:14:21.764328Z","iopub.status.idle":"2026-02-04T05:14:21.770406Z","shell.execute_reply.started":"2026-02-04T05:14:21.764302Z","shell.execute_reply":"2026-02-04T05:14:21.769678Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor([[0., 0., 0.],\n        [0., 0., 0.]], device='cuda:0')"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# GPU не безлимитна. Хочется узнать, сколько ресурсов GPU мы занимаем.\n# Для этого есть nvidia-smi\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:15:01.588553Z","iopub.execute_input":"2026-02-04T05:15:01.589406Z","iopub.status.idle":"2026-02-04T05:15:01.771672Z","shell.execute_reply.started":"2026-02-04T05:15:01.589375Z","shell.execute_reply":"2026-02-04T05:15:01.770790Z"}},"outputs":[{"name":"stdout","text":"Wed Feb  4 05:15:01 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n+-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   33C    P0             33W /  250W |     291MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Видим, что процесс python3.10 что-то занимает. Это как раз наши тензоры.\n# У вас будут другие числа - все сильно зависит от модели видеокарты и операционной системы.","metadata":{},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"В чем же такой плюс от работы на GPU?\n\nДавайте увидим сами. Возьмем большой тензор и начнем его умножать большое число раз.","metadata":{}},{"cell_type":"code","source":"# Используем benchmark из pytorch - он сделает \"честное\" вычисление (без кешей, с прогревом и т.п.)\n# Подробнее про benchmark в PyTorch: https://pytorch.org/tutorials/recipes/recipes/benchmark.html\nimport torch.utils.benchmark as benchmark\n\nnum_channels = 1024\nmany_layers = nn.Sequential(*[nn.Linear(num_channels, num_channels)] * 100)\ndata = torch.randn((3000, num_channels))\n# Прогоним через слой 5 раз и подсчитаем среднее/дисперсию\nt = benchmark.Timer(\n    stmt=\"many_layers(data)\",\n    globals={\"many_layers\": many_layers, \"data\": data},\n    # заметьте, используем 8 ядер процессора\n    num_threads=8,\n)\nprint(t.timeit(5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:27:22.183292Z","iopub.execute_input":"2026-02-04T05:27:22.183946Z","iopub.status.idle":"2026-02-04T05:27:44.214712Z","shell.execute_reply.started":"2026-02-04T05:27:22.183917Z","shell.execute_reply":"2026-02-04T05:27:44.214081Z"}},"outputs":[{"name":"stdout","text":"<torch.utils.benchmark.utils.common.Measurement object at 0x7c4dc17bbfe0>\nmany_layers(data)\n  3.04 s\n  1 measurement, 5 runs , 8 threads\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Повторим эксперимент, но уже на GPU\n\nmany_layers_gpu = many_layers.to(\"cuda\")\ndata_gpu = data.to(\"cuda\")\nt = benchmark.Timer(\n    stmt=\"many_layers_gpu(data_gpu)\",\n    globals={\"many_layers_gpu\": many_layers_gpu, \"data_gpu\": data_gpu},\n)\nprint(t.timeit(5))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:29:00.691928Z","iopub.execute_input":"2026-02-04T05:29:00.692582Z","iopub.status.idle":"2026-02-04T05:29:01.273892Z","shell.execute_reply.started":"2026-02-04T05:29:00.692553Z","shell.execute_reply":"2026-02-04T05:29:01.273293Z"}},"outputs":[{"name":"stdout","text":"<torch.utils.benchmark.utils.common.Measurement object at 0x7c4dfffe52b0>\nmany_layers_gpu(data_gpu)\n  80.02 ms\n  1 measurement, 5 runs , 1 thread\n","output_type":"stream"}],"execution_count":26},{"cell_type":"markdown","source":"В 30 раз быстрее! И это только игрушечный пример.\nВ реальных сетях разница может быть еще больше.\n\nВ чем же подвох? Почему бы все не учить на видеокарте?\nЕсть две причины, которые остановят нас:\n1. У видеокарты очень мало оперативной памяти по сравнению с сервером.\nНа сервере вы можете поставить и 512 Гб оперативной памяти, и даже 1 Тб.\nНо на видеокарте сейчас можно ставить до 80 Гб (Tesla H800).\n2. На видеокарте не очень информативные ошибки. Это особенность программы CUDA,\nкоторую PyTorch использует для вычислений на видеокарте.\n\nПервая проблема фундаментальная, ее решают через распределение нагрузки по нескольким видеокартам.\nЭто делать сложно: нужно научить несколько GPU взаимодействовать друг с другом, распределять равномерно нагрузку\nи синхронизировать работу.\nНа первых порах вам вряд ли придется столкнуться с такой задачей, поэтому пока оставим эту тему.\n\nРассмотрим вторую проблему с неинформативными ошибками.","metadata":{}},{"cell_type":"code","source":"# Подсчитаем Binary Cross Entropy loss с элементами вне {0, 1}\nnn.BCELoss()(torch.arange(2, 3).float(), torch.arange(2, 3).float())","metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"all elements of input should be between 0 and 1","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[45], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Подсчитаем Binary Cross Entropy loss с элементами вне {0, 1}\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBCELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.cache/pypoetry/virtualenvs/start-dl-fEQaQ9Q8-py3.10/lib/python3.10/site-packages/torch/nn/functional.py:3127\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3124\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3125\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[0;32m-> 3127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: all elements of input should be between 0 and 1"]}],"execution_count":45},{"cell_type":"code","source":"# То же самое, но тензор на GPU\nnn.BCELoss()(torch.arange(2, 3).float().cuda(), torch.arange(2, 3).float().cuda())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:29:37.022472Z","iopub.execute_input":"2026-02-04T05:29:37.022789Z","iopub.status.idle":"2026-02-04T05:29:37.183001Z","shell.execute_reply.started":"2026-02-04T05:29:37.022764Z","shell.execute_reply":"2026-02-04T05:29:37.182018Z"}},"outputs":[{"name":"stderr","text":"/pytorch/aten/src/ATen/native/cuda/Loss.cu:90: operator(): block: [0,0,0], thread: [0,0,0] Assertion `input_val >= zero && input_val <= one` failed.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/2270901221.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# То же самое, но тензор на GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m         return F.binary_cross_entropy(\n\u001b[0m\u001b[1;32m    707\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3528\u001b[0m         \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3530\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"AcceleratorError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}],"execution_count":27},{"cell_type":"code","source":"# Более того - после ошибки уже ничего нельзя сделать с видеокартой.\n# Придется перезапускать ноутбук :(\ntorch.randn((2, 3), device='cuda')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T05:30:53.944680Z","iopub.execute_input":"2026-02-04T05:30:53.945039Z","iopub.status.idle":"2026-02-04T05:30:53.975324Z","shell.execute_reply.started":"2026-02-04T05:30:53.945011Z","shell.execute_reply":"2026-02-04T05:30:53.974511Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1648402148.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Более того - после ошибки уже ничего нельзя сделать с видеокартой.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Придется перезапускать ноутбук :(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"],"ename":"AcceleratorError","evalue":"CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n","output_type":"error"}],"execution_count":28},{"cell_type":"markdown","source":"Из-за таких проблем на видеокарте не рекомендуется отлаживать модели (об этом говорили в лекции).","metadata":{}}]}